{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: Baseline Model Training\n",
    "\n",
    "This notebook trains the baseline models:\n",
    "1. GMF (Generalized Matrix Factorization)\n",
    "2. MLP (Multi-Layer Perceptron)\n",
    "3. NeuMF (Neural Matrix Factorization)\n",
    "\n",
    "And evaluates their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.config import config\n",
    "from src.models.gmf import GMF\n",
    "from src.models.mlp import MLP\n",
    "from src.models.neumf import NeuMF\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model\n",
    "from src.negative_sampling import build_user_history\n",
    "\n",
    "# Set device\n",
    "config._set_device()\n",
    "print(f\"Using device: {config.train.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "train_df = pd.read_pickle(config.paths.train_path)\n",
    "val_df = pd.read_pickle(config.paths.val_path)\n",
    "test_df = pd.read_pickle(config.paths.test_path)\n",
    "\n",
    "# Load mappings\n",
    "import pickle\n",
    "with open(config.paths.mappings_path, 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "num_users = mappings['num_users']\n",
    "num_items = mappings['num_items']\n",
    "num_genres = mappings['num_genres']\n",
    "\n",
    "print(f\"Dataset: {num_users:,} users, {num_items:,} items, {num_genres} genres\")\n",
    "print(f\"Train: {len(train_df):,} ratings\")\n",
    "print(f\"Val: {len(val_df):,} ratings\")\n",
    "print(f\"Test: {len(test_df):,} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract arrays\n",
    "train_users = train_df['userId'].values\n",
    "train_items = train_df['movieId'].values\n",
    "\n",
    "val_users = val_df['userId'].values\n",
    "val_items = val_df['movieId'].values\n",
    "\n",
    "test_users = test_df['userId'].values\n",
    "test_items = test_df['movieId'].values\n",
    "\n",
    "# Build user history for evaluation\n",
    "user_history = build_user_history(train_users, train_items)\n",
    "\n",
    "print(\"Data prepared for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING GMF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create model\n",
    "gmf_model = GMF(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    embedding_dim=config.model.USER_EMBEDDING_DIM,\n",
    "    hidden_dim=config.model.GMF_HIDDEN_DIM,\n",
    ")\n",
    "\n",
    "print(f\"GMF parameters: {gmf_model.count_parameters():,}\")\n",
    "\n",
    "# Train\n",
    "gmf_history = train_model(\n",
    "    model=gmf_model,\n",
    "    train_users=train_users,\n",
    "    train_items=train_items,\n",
    "    val_data={\n",
    "        'users': val_users,\n",
    "        'items': val_items,\n",
    "    },\n",
    "    num_items=num_items,\n",
    "    num_epochs=config.train.NUM_EPOCHS,\n",
    "    batch_size=config.train.BATCH_SIZE,\n",
    "    learning_rate=config.train.LEARNING_RATE,\n",
    "    weight_decay=config.train.WEIGHT_DECAY,\n",
    "    num_negatives=config.train.NUM_NEGATIVES,\n",
    "    device=config.train.DEVICE,\n",
    "    save_dir=config.paths.TRAINED_MODELS_DIR,\n",
    "    early_stopping_patience=config.train.EARLY_STOPPING_PATIENCE,\n",
    "    log_dir=config.paths.TENSORBOARD_LOG_DIR + \"/gmf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MLP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create model\n",
    "mlp_model = MLP(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    embedding_dim=config.model.USER_EMBEDDING_DIM,\n",
    "    hidden_dims=config.model.MLP_HIDDEN_DIMS,\n",
    "    dropout=config.model.MLP_DROPOUT,\n",
    ")\n",
    "\n",
    "print(f\"MLP parameters: {mlp_model.count_parameters():,}\")\n",
    "\n",
    "# Train\n",
    "mlp_history = train_model(\n",
    "    model=mlp_model,\n",
    "    train_users=train_users,\n",
    "    train_items=train_items,\n",
    "    val_data={\n",
    "        'users': val_users,\n",
    "        'items': val_items,\n",
    "    },\n",
    "    num_items=num_items,\n",
    "    num_epochs=config.train.NUM_EPOCHS,\n",
    "    batch_size=config.train.BATCH_SIZE,\n",
    "    learning_rate=config.train.LEARNING_RATE,\n",
    "    weight_decay=config.train.WEIGHT_DECAY,\n",
    "    num_negatives=config.train.NUM_NEGATIVES,\n",
    "    device=config.train.DEVICE,\n",
    "    save_dir=config.paths.TRAINED_MODELS_DIR,\n",
    "    early_stopping_patience=config.train.EARLY_STOPPING_PATIENCE,\n",
    "    log_dir=config.paths.TENSORBOARD_LOG_DIR + \"/mlp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING NeuMF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create model\n",
    "neumf_model = NeuMF(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    embedding_dim=config.model.USER_EMBEDDING_DIM,\n",
    "    gmf_hidden_dim=config.model.GMF_HIDDEN_DIM,\n",
    "    mlp_hidden_dims=config.model.MLP_HIDDEN_DIMS,\n",
    "    mlp_dropout=config.model.MLP_DROPOUT,\n",
    "    fusion_dim=config.model.NEUMF_FUSION_DIM,\n",
    ")\n",
    "\n",
    "print(f\"NeuMF parameters: {neumf_model.count_parameters():,}\")\n",
    "\n",
    "# Train\n",
    "neumf_history = train_model(\n",
    "    model=neumf_model,\n",
    "    train_users=train_users,\n",
    "    train_items=train_items,\n",
    "    val_data={\n",
    "        'users': val_users,\n",
    "        'items': val_items,\n",
    "    },\n",
    "    num_items=num_items,\n",
    "    num_epochs=config.train.NUM_EPOCHS,\n",
    "    batch_size=config.train.BATCH_SIZE,\n",
    "    learning_rate=config.train.LEARNING_RATE,\n",
    "    weight_decay=config.train.WEIGHT_DECAY,\n",
    "    num_negatives=config.train.NUM_NEGATIVES,\n",
    "    device=config.train.DEVICE,\n",
    "    save_dir=config.paths.TRAINED_MODELS_DIR,\n",
    "    early_stopping_patience=config.train.EARLY_STOPPING_PATIENCE,\n",
    "    log_dir=config.paths.TENSORBOARD_LOG_DIR + \"/neumf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best models and evaluate\n",
    "models = {\n",
    "    'GMF': GMF.load(f\"{config.paths.TRAINED_MODELS_DIR}/GMF_best.pt\", GMF, num_users=num_users, num_items=num_items),\n",
    "    'MLP': MLP.load(f\"{config.paths.TRAINED_MODELS_DIR}/MLP_best.pt\", MLP, num_users=num_users, num_items=num_items),\n",
    "    'NeuMF': NeuMF.load(f\"{config.paths.TRAINED_MODELS_DIR}/NeuMF_best.pt\", NeuMF, num_users=num_users, num_items=num_items),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    metrics = evaluate_model(\n",
    "        model=model,\n",
    "        users=test_users,\n",
    "        items=test_items,\n",
    "        k_values=config.eval.K_VALUES,\n",
    "        device=config.train.DEVICE,\n",
    "        num_items=num_items,\n",
    "        user_history=user_history,\n",
    "    )\n",
    "    results[name] = metrics\n",
    "    print(f\"  HR@10: {metrics['hr@10']:.4f}\")\n",
    "    print(f\"  NDCG@10: {metrics['ndcg@10']:.4f}\")\n",
    "    print(f\"  AUC: {metrics['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
