{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCF Movie Recommender - Model Inference on Colab\n",
    "\n",
    "This notebook demonstrates how to use trained NCF/NeuMF+ models for movie recommendations.\n",
    "\n",
    "**Features:**\n",
    "- Load trained models from Google Drive\n",
    "- Generate top-K movie recommendations for users\n",
    "- Predict scores for user-item pairs\n",
    "- Handle cold-start scenarios (new movies)\n",
    "- Display movie titles and genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup - Mount Google Drive\n\nThis notebook expects your trained models and data to be in Google Drive.\n\n**Required structure in Google Drive:**\n```\nMyDrive/\n‚îî‚îÄ‚îÄ NCF-Movie-Recommender/\n    ‚îú‚îÄ‚îÄ data/                    # Processed data files\n    ‚îÇ   ‚îú‚îÄ‚îÄ mappings.pkl         # User/item mappings\n    ‚îÇ   ‚îú‚îÄ‚îÄ item_synopsis_embeddings.npy\n    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n    ‚îú‚îÄ‚îÄ datasets/                # Raw datasets\n    ‚îÇ   ‚îî‚îÄ‚îÄ movies_metadata.csv  # Movie titles and info\n    ‚îî‚îÄ‚îÄ experiments/\n        ‚îî‚îÄ‚îÄ trained_models/      # Trained model checkpoints\n            ‚îú‚îÄ‚îÄ NeuMFPlus_genre_synopsis_best.pt\n            ‚îî‚îÄ‚îÄ ...\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Paths\n",
    "\n",
    "Update these paths to match your Google Drive structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Configure paths\nimport os\n\n# @markdown **Base path for NCF-Movie-Recommender project:**\nGDRIVE_BASE = \"/content/drive/MyDrive/NCF-Movie-Recommender\"  # @param {type:\"string\"}\n\n# Paths relative to your Google Drive base\nDATA_DIR = os.path.join(GDRIVE_BASE, \"data\")\nDATASETS_DIR = os.path.join(GDRIVE_BASE, \"datasets\")\nMODELS_DIR = os.path.join(GDRIVE_BASE, \"experiments\", \"trained_models\")\n\nprint(f\"üìÅ Base directory: {GDRIVE_BASE}\")\nprint(f\"üìÅ Data directory: {DATA_DIR}\")\nprint(f\"üìÅ Datasets directory: {DATASETS_DIR}\")\nprint(f\"üìÅ Models directory: {MODELS_DIR}\")\n\n# Verify directories exist\nif os.path.exists(DATA_DIR):\n    data_files = os.listdir(DATA_DIR)\n    print(f\"\\n‚úÖ Data directory found! Files: {len(data_files)}\")\nelse:\n    print(f\"\\n‚ùå Data directory not found: {DATA_DIR}\")\n\nif os.path.exists(DATASETS_DIR):\n    datasets_files = os.listdir(DATASETS_DIR)\n    print(f\"‚úÖ Datasets directory found! Files: {len(datasets_files)}\")\nelse:\n    print(f\"‚ùå Datasets directory not found: {DATASETS_DIR}\")\n\nif os.path.exists(MODELS_DIR):\n    model_files = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n    print(f\"‚úÖ Models directory found! Checkpoints: {len(model_files)}\")\n    if model_files:\n        print(\"\\nAvailable models:\")\n        for f in sorted(model_files):\n            print(f\"  ‚Ä¢ {f}\")\nelse:\n    print(f\"\\n‚ùå Models directory not found: {MODELS_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Install required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install -q torch numpy pandas sentence-transformers tqdm\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"   Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Model Architecture\n",
    "\n",
    "This section defines the NeuMF+ model architecture to match your trained checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Define NeuMF+ Model (matching trained checkpoints)\nimport torch.nn as nn\n\nclass ContentEncoder(nn.Module):\n    \"\"\"Encode content features (genre + synopsis) into embeddings.\"\"\"\n    \n    def __init__(self, num_genres: int, genre_embed_dim: int = 64,\n                 synopsis_embed_dim: int = 384, content_embed_dim: int = 256,\n                 dropout: float = 0.1):\n        super().__init__()\n        \n        self.genre_encoder = nn.Sequential(\n            nn.Linear(num_genres, genre_embed_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n        )\n        \n        self.synopsis_projection = nn.Sequential(\n            nn.Linear(synopsis_embed_dim, synopsis_embed_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n        )\n        \n        combined_dim = genre_embed_dim + synopsis_embed_dim // 2\n        self.content_encoder = nn.Sequential(\n            nn.Linear(combined_dim, content_embed_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n        )\n    \n    def forward(self, genre_features, synopsis_embeddings):\n        genre_embed = self.genre_encoder(genre_features)\n        synopsis_embed = self.synopsis_projection(synopsis_embeddings)\n        combined = torch.cat([genre_embed, synopsis_embed], dim=-1)\n        return self.content_encoder(combined)\n\n\nclass GatedFusion(nn.Module):\n    \"\"\"Gated fusion for CF and content embeddings.\"\"\"\n    \n    def __init__(self, cf_dim: int, content_dim: int, hidden_dim: int = 64, dropout: float = 0.1):\n        super().__init__()\n        \n        self.gate_network = nn.Sequential(\n            nn.Linear(cf_dim + content_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, 1),\n            nn.Sigmoid(),\n        )\n    \n    def forward(self, cf_embed, content_embed):\n        combined = torch.cat([cf_embed, content_embed], dim=-1)\n        gate = self.gate_network(combined)\n        \n        if cf_embed.shape[-1] != content_embed.shape[-1]:\n            if cf_embed.shape[-1] > content_embed.shape[-1]:\n                target_dim = cf_embed.shape[-1]\n                if not hasattr(self, '_content_proj'):\n                    self._content_proj = nn.Linear(content_embed.shape[-1], target_dim).to(cf_embed.device)\n                content_embed = self._content_proj(content_embed)\n            else:\n                target_dim = content_embed.shape[-1]\n                if not hasattr(self, '_cf_proj'):\n                    self._cf_proj = nn.Linear(cf_embed.shape[-1], target_dim).to(cf_embed.device)\n                cf_embed = self._cf_proj(cf_embed)\n        \n        fused = gate * cf_embed + (1 - gate) * content_embed\n        return fused, gate\n\n\nclass NeuMFPlus(nn.Module):\n    \"\"\"NeuMF+ with Genre, Synopsis, and Gated Fusion.\"\"\"\n    \n    def __init__(\n        self,\n        num_users: int,\n        num_items: int,\n        num_genres: int,\n        # CF (NeuMF) parameters\n        embedding_dim: int = 32,\n        gmf_hidden_dim: int = 8,\n        mlp_hidden_dims: list = None,\n        mlp_dropout: float = 0.2,\n        fusion_dim: int = 32,\n        # Content encoder parameters\n        genre_embed_dim: int = 64,\n        synopsis_embed_dim: int = 384,\n        content_embed_dim: int = 256,\n        content_encoder_dropout: float = 0.1,\n        # Gated fusion parameters\n        gated_fusion_hidden_dim: int = 64,\n        gated_fusion_dropout: float = 0.1,\n        # Output parameters\n        output_hidden_dim: int = 64,\n        output_dropout: float = 0.2,\n        # Ablation study flags\n        use_genre: bool = True,\n        use_synopsis: bool = True,\n        use_gated_fusion: bool = True,\n    ):\n        super().__init__()\n\n        self.num_users = num_users\n        self.num_items = num_items\n        self.num_genres = num_genres\n        self.embedding_dim = embedding_dim\n        self.use_genre = use_genre\n        self.use_synopsis = use_synopsis\n        self.use_gated_fusion = use_gated_fusion\n        self.synopsis_embed_dim = synopsis_embed_dim\n        self.content_embed_dim = content_embed_dim\n\n        # Calculate content dimensions\n        if use_genre and use_synopsis:\n            self.content_encoder = ContentEncoder(\n                num_genres=num_genres,\n                genre_embed_dim=genre_embed_dim,\n                synopsis_embed_dim=synopsis_embed_dim,\n                content_embed_dim=content_embed_dim,\n                dropout=content_encoder_dropout,\n            )\n            actual_content_dim = content_embed_dim\n        elif use_genre:\n            self.genre_encoder = nn.Sequential(\n                nn.Linear(num_genres, genre_embed_dim),\n                nn.ReLU(),\n                nn.Dropout(content_encoder_dropout),\n            )\n            actual_content_dim = genre_embed_dim\n        elif use_synopsis:\n            self.synopsis_projection = nn.Sequential(\n                nn.Linear(synopsis_embed_dim, synopsis_embed_dim // 2),\n                nn.ReLU(),\n                nn.Dropout(content_encoder_dropout),\n            )\n            actual_content_dim = synopsis_embed_dim // 2\n        else:\n            actual_content_dim = 0\n\n        # CF (NeuMF) branch - separate embeddings for GMF and MLP\n        self.gmf_user_embedding = nn.Embedding(num_users, embedding_dim)\n        self.gmf_item_embedding = nn.Embedding(num_items, embedding_dim)\n        self.mlp_user_embedding = nn.Embedding(num_users, embedding_dim)\n        self.mlp_item_embedding = nn.Embedding(num_items, embedding_dim)\n\n        # Initialize embeddings\n        nn.init.xavier_uniform_(self.gmf_user_embedding.weight)\n        nn.init.xavier_uniform_(self.gmf_item_embedding.weight)\n        nn.init.xavier_uniform_(self.mlp_user_embedding.weight)\n        nn.init.xavier_uniform_(self.mlp_item_embedding.weight)\n\n        # GMF branch\n        self.gmf_fc = nn.Linear(embedding_dim, gmf_hidden_dim)\n\n        # MLP branch\n        mlp_hidden_dims = mlp_hidden_dims or [128, 64, 32]\n        mlp_input_dim = 2 * embedding_dim\n        self.mlp_layers = nn.ModuleList()\n        self.mlp_dropout_layers = nn.ModuleList()\n\n        prev_dim = mlp_input_dim\n        for hidden_dim in mlp_hidden_dims:\n            self.mlp_layers.append(nn.Linear(prev_dim, hidden_dim))\n            self.mlp_dropout_layers.append(nn.Dropout(mlp_dropout))\n            prev_dim = hidden_dim\n\n        # NeuMF fusion layer\n        self.neumf_fusion_fc = nn.Linear(gmf_hidden_dim + prev_dim, fusion_dim)\n        self.neumf_fusion_dropout = nn.Dropout(0.1)\n        self.cf_output_dim = fusion_dim\n\n        # Content fusion\n        if actual_content_dim > 0:\n            if use_gated_fusion:\n                self.gated_fusion = GatedFusion(\n                    cf_dim=self.cf_output_dim,\n                    content_dim=actual_content_dim,\n                    hidden_dim=gated_fusion_hidden_dim,\n                    dropout=gated_fusion_dropout,\n                )\n                self.final_input_dim = max(self.cf_output_dim, actual_content_dim)\n            else:\n                self.final_input_dim = self.cf_output_dim + actual_content_dim\n        else:\n            self.final_input_dim = self.cf_output_dim\n\n        # Output layers\n        self.output_fc = nn.Sequential(\n            nn.Linear(self.final_input_dim, output_hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(output_dropout),\n            nn.Linear(output_hidden_dim, 1),\n        )\n\n        self._init_weights()\n\n    def _init_weights(self) -> None:\n        \"\"\"Initialize weights.\"\"\"\n        if self.use_genre and not self.use_synopsis:\n            if hasattr(self, 'genre_encoder'):\n                for module in self.genre_encoder:\n                    if isinstance(module, nn.Linear):\n                        nn.init.xavier_uniform_(module.weight)\n                        if module.bias is not None:\n                            nn.init.zeros_(module.bias)\n\n        if self.use_synopsis and not self.use_genre:\n            if hasattr(self, 'synopsis_projection'):\n                for module in self.synopsis_projection:\n                    if isinstance(module, nn.Linear):\n                        nn.init.xavier_uniform_(module.weight)\n                        if module.bias is not None:\n                            nn.init.zeros_(module.bias)\n\n        nn.init.xavier_uniform_(self.gmf_fc.weight)\n        nn.init.zeros_(self.gmf_fc.bias)\n\n        for layer in self.mlp_layers:\n            nn.init.xavier_uniform_(layer.weight)\n            nn.init.zeros_(layer.bias)\n\n        nn.init.xavier_uniform_(self.neumf_fusion_fc.weight)\n        nn.init.zeros_(self.neumf_fusion_fc.bias)\n\n        for module in self.output_fc:\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n\n    def forward(\n        self,\n        user_ids: torch.Tensor,\n        item_ids: torch.Tensor,\n        genre_features: torch.Tensor = None,\n        synopsis_embeddings: torch.Tensor = None,\n        return_gate: bool = False,\n    ) -> torch.Tensor:\n        \"\"\"Forward pass of NeuMF+.\"\"\"\n        # GMF\n        gmf_user_embed = self.gmf_user_embedding(user_ids)\n        gmf_item_embed = self.gmf_item_embedding(item_ids)\n        gmf_output = gmf_user_embed * gmf_item_embed\n        gmf_hidden = self.gmf_fc(gmf_output)\n\n        # MLP\n        mlp_user_embed = self.mlp_user_embedding(user_ids)\n        mlp_item_embed = self.mlp_item_embedding(item_ids)\n        mlp_concat = torch.cat([mlp_user_embed, mlp_item_embed], dim=-1)\n\n        x = mlp_concat\n        for layer, dropout in zip(self.mlp_layers, self.mlp_dropout_layers):\n            x = layer(x)\n            x = torch.relu(x)\n            x = dropout(x)\n\n        mlp_hidden = x\n\n        # NeuMF fusion\n        neumf_input = torch.cat([gmf_hidden, mlp_hidden], dim=-1)\n        cf_embed = self.neumf_fusion_fc(neumf_input)\n        cf_embed = torch.relu(cf_embed)\n        cf_embed = self.neumf_fusion_dropout(cf_embed)\n\n        # Content Branch\n        content_embed = None\n        if self.use_genre and self.use_synopsis:\n            if genre_features is None or synopsis_embeddings is None:\n                batch_size = user_ids.size(0)\n                device = user_ids.device\n                if genre_features is None:\n                    genre_features = torch.zeros(batch_size, self.num_genres, device=device)\n                if synopsis_embeddings is None:\n                    synopsis_embeddings = torch.zeros(batch_size, self.synopsis_embed_dim, device=device)\n            content_embed = self.content_encoder(genre_features, synopsis_embeddings)\n        elif self.use_genre:\n            if genre_features is None:\n                batch_size = user_ids.size(0)\n                device = user_ids.device\n                genre_features = torch.zeros(batch_size, self.num_genres, device=device)\n            content_embed = self.genre_encoder(genre_features)\n        elif self.use_synopsis:\n            if synopsis_embeddings is None:\n                batch_size = user_ids.size(0)\n                device = user_ids.device\n                synopsis_embeddings = torch.zeros(batch_size, self.synopsis_embed_dim, device=device)\n            content_embed = self.synopsis_projection(synopsis_embeddings)\n\n        # Fusion\n        if content_embed is not None:\n            if self.use_gated_fusion:\n                final_embed, gate = self.gated_fusion(cf_embed, content_embed)\n            else:\n                final_embed = torch.cat([cf_embed, content_embed], dim=-1)\n                gate = None\n        else:\n            final_embed = cf_embed\n            gate = None\n\n        # Output\n        output = self.output_fc(final_embed)\n\n        if return_gate:\n            return output, gate\n        return output\n\n    @classmethod\n    def load(cls, checkpoint_path: str, device: str = 'cuda'):\n        \"\"\"Load model from checkpoint.\"\"\"\n        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n        config = checkpoint['model_config']\n\n        model = cls(\n            num_users=config['num_users'],\n            num_items=config['num_items'],\n            num_genres=config['num_genres'],\n            use_genre=config['use_genre'],\n            use_synopsis=config['use_synopsis'],\n            use_gated_fusion=config['use_gated_fusion'],\n        )\n\n        # Load state_dict with strict=False to handle version mismatches\n        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n        model = model.to(device)\n\n        return model, checkpoint\n\nprint(\"‚úÖ Model architecture defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data and Mappings\n",
    "\n",
    "Load the processed data files including mappings, genre features, and movie metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Load mappings and features\n\n# Load mappings\nmappings_path = os.path.join(DATA_DIR, \"mappings.pkl\")\nwith open(mappings_path, 'rb') as f:\n    mappings = pickle.load(f)\n\nNUM_USERS = mappings['num_users']\nNUM_ITEMS = mappings['num_items']\nNUM_GENRES = mappings['num_genres']\nGENRE_NAMES = mappings.get('genre_names', [])\n\nprint(f\"‚úÖ Mappings loaded!\")\nprint(f\"   Users: {NUM_USERS:,}\")\nprint(f\"   Items: {NUM_ITEMS:,}\")\nprint(f\"   Genres: {NUM_GENRES}\")\nif GENRE_NAMES:\n    print(f\"   Genre names: {GENRE_NAMES}\")\n\n# Load genre features (if available)\n# Note: This file may not exist - genre features can be generated from movies_metadata.csv\ngenre_path = os.path.join(DATA_DIR, \"item_genre_features.npy\")\nif os.path.exists(genre_path):\n    GENRE_FEATURES = np.load(genre_path)\n    print(f\"\\n‚úÖ Genre features loaded: {GENRE_FEATURES.shape}\")\nelse:\n    GENRE_FEATURES = None\n    print(f\"\\n‚ö†Ô∏è  Genre features not found: {genre_path}\")\n    print(f\"   Models that require genre features will use zero vectors.\")\n\n# Load synopsis embeddings\n# Note: File uses plural \"embeddings\"\nsynopsis_path = os.path.join(DATA_DIR, \"item_synopsis_embeddings.npy\")\nif os.path.exists(synopsis_path):\n    SYNOPSIS_EMBEDDINGS = np.load(synopsis_path)\n    print(f\"‚úÖ Synopsis embeddings loaded: {SYNOPSIS_EMBEDDINGS.shape}\")\nelse:\n    SYNOPSIS_EMBEDDINGS = None\n    print(f\"‚ö†Ô∏è  Synopsis embeddings not found: {synopsis_path}\")\n\n# Load movie metadata for display (from datasets directory)\nmetadata_path = os.path.join(DATASETS_DIR, \"movies_metadata.csv\")\nif os.path.exists(metadata_path):\n    movies_df = pd.read_csv(metadata_path, low_memory=False)\n    # Filter for valid IDs\n    movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n    movies_df = movies_df[movies_df['id'].notna()]\n    movies_df['id'] = movies_df['id'].astype(int)\n    movies_df = movies_df.set_index('id')\n    print(f\"\\n‚úÖ Movie metadata loaded: {len(movies_df):,} movies\")\nelse:\n    movies_df = None\n    print(f\"\\n‚ö†Ô∏è  Movie metadata not found: {metadata_path}\")\n\n# Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATA LOADING SUMMARY\")\nprint(\"=\"*70)\nprint(f\"Genre features available: {'‚úÖ Yes' if GENRE_FEATURES is not None else '‚ùå No'}\")\nprint(f\"Synopsis embeddings available: {'‚úÖ Yes' if SYNOPSIS_EMBEDDINGS is not None else '‚ùå No'}\")\nprint(f\"Movie metadata available: {'‚úÖ Yes' if movies_df is not None else '‚ùå No'}\")\n\nif GENRE_FEATURES is None:\n    print(\"\\n‚ö†Ô∏è  NOTE: Genre features file (item_genre_features.npy) not found.\")\n    print(\"   If you're using a model that requires genre features,\")\n    print(\"   the model will automatically use zero vectors for missing features.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Load Trained Model\n\nSelect and load one of your trained models.\n\n**Available Models:**\n| Model | Description | Features |\n|-------|-------------|----------|\n| `NeuMF_best.pt` | Baseline | Collaborative Filtering only |\n| `NeuMFPlus_genre_best.pt` | Genre-enhanced | CF + Genre features |\n| `NeuMFPlus_genre_synopsis_bestt.pt` | Full model | CF + Genre + Synopsis |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Load trained model\n# @markdown Select the model checkpoint to load:\n\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\n# Get available models\navailable_models = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n\n# Model descriptions\nMODEL_INFO = {\n    'NeuMF_best.pt': {\n        'name': 'NeuMF (Baseline)',\n        'description': 'Collaborative Filtering only - no content features',\n        'features': 'User-Item interactions only'\n    },\n    'NeuMFPlus_genre_best.pt': {\n        'name': 'NeuMF+ (Genre)',\n        'description': 'CF + Genre features',\n        'features': 'User-Item + Movie genres'\n    },\n    'NeuMFPlus_genre_synopsis_bestt.pt': {\n        'name': 'NeuMF+ (Genre + Synopsis)',\n        'description': 'CF + Genre + Synopsis features (Full Model)',\n        'features': 'User-Item + Genres + Movie synopsis'\n    }\n}\n\nif not available_models:\n    print(f\"‚ùå No models found in {MODELS_DIR}\")\nelse:\n    # Create dropdown with model descriptions\n    model_options = [(f\"{m}  ({MODEL_INFO.get(m, {}).get('name', m)})\", m) for m in sorted(available_models)]\n    \n    model_dropdown = widgets.Dropdown(\n        options=model_options,\n        description='Select model:',\n        style={'description_width': 'initial'},\n    )\n    display(model_dropdown)\n    \n    # Model info display\n    info_out = widgets.Output()\n    display(info_out)\n    \n    def show_model_info(change):\n        with info_out:\n            info_out.clear_output()\n            model_name = change['new']\n            info = MODEL_INFO.get(model_name, {})\n            if info:\n                print(f\"üìã {info.get('name', model_name)}\")\n                print(f\"   {info.get('description', '')}\")\n                print(f\"   Features: {info.get('features', 'N/A')}\")\n    \n    model_dropdown.observe(show_model_info, names='value')\n    # Show initial info\n    show_model_info({'new': model_dropdown.value})\n    \n    # Load button\n    load_btn = widgets.Button(description='Load Model', button_style='primary')\n    display(load_btn)\n    \n    # Output area\n    out = widgets.Output()\n    display(out)\n    \n    def load_model(b):\n        with out:\n            out.clear_output()\n            model_name = model_dropdown.value\n            checkpoint_path = os.path.join(MODELS_DIR, model_name)\n            \n            print(f\"Loading model from: {model_name}\")\n            print(f\"Path: {checkpoint_path}\")\n            \n            global model, checkpoint, model_config\n            model, checkpoint = NeuMFPlus.load(checkpoint_path, device=DEVICE)\n            model.eval()\n            model_config = checkpoint['model_config']\n            \n            print(\"\\n\" + \"=\"*70)\n            print(\"MODEL CONFIGURATION\")\n            print(\"=\"*70)\n            print(f\"use_genre: {model_config.get('use_genre')}\")\n            print(f\"use_synopsis: {model_config.get('use_synopsis')}\")\n            print(f\"use_gated_fusion: {model_config.get('use_gated_fusion')}\")\n            print(f\"\\nParameters: {sum(p.numel() for p in model.parameters()):,}\")\n            \n            if 'metrics' in checkpoint:\n                print(\"\\nValidation Metrics:\")\n                for k, v in checkpoint['metrics'].items():\n                    if isinstance(v, (int, float)):\n                        print(f\"  {k}: {v:.4f}\")\n            \n            # Show what features are needed\n            print(\"\\n\" + \"-\"*70)\n            print(\"REQUIRED FEATURES FOR INFERENCE:\")\n            if model_config.get('use_genre'):\n                print(\"  ‚úÖ Genre features (item_genre_features.npy)\")\n            else:\n                print(\"  ‚ùå Genre features NOT needed\")\n            if model_config.get('use_synopsis'):\n                print(\"  ‚úÖ Synopsis embeddings (item_synopsis_embeddings.npy)\")\n            else:\n                print(\"  ‚ùå Synopsis embeddings NOT needed\")\n            print(\"-\"*70)\n            \n            print(\"\\n‚úÖ Model loaded successfully!\")\n    \n    load_btn.on_click(load_model)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Helper Functions\n",
    "\n",
    "Define helper functions for prediction and recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Define helper functions\n\ndef get_movie_title(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n    \"\"\"Get movie title for item ID.\"\"\"\n    if movies_df is None:\n        return f\"Movie {item_id}\"\n    \n    # Try to get title from movies_df\n    if item_id in movies_df.index:\n        title = movies_df.loc[item_id, 'title']\n        return title if pd.notna(title) else f\"Movie {item_id}\"\n    \n    return f\"Movie {item_id}\"\n\n\ndef parse_genres(genres_str: str) -> list:\n    \"\"\"Parse genres from JSON string.\"\"\"\n    import json\n    import ast\n    \n    if pd.isna(genres_str) or genres_str == \"\":\n        return []\n    \n    try:\n        genres = json.loads(genres_str)\n        return [g['name'] for g in genres]\n    except:\n        try:\n            genres = ast.literal_eval(genres_str)\n            return [g['name'] for g in genres]\n        except:\n            return []\n\n\ndef get_movie_genres(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n    \"\"\"Get genres for item ID.\"\"\"\n    if movies_df is None or GENRE_FEATURES is None:\n        return \"Unknown\"\n    \n    if item_id in movies_df.index:\n        genres_str = movies_df.loc[item_id, 'genres']\n        genres = parse_genres(genres_str)\n        return ', '.join(genres) if genres else \"Unknown\"\n    \n    # Use genre features if available\n    if item_id < len(GENRE_FEATURES):\n        genre_indices = [i for i, g in enumerate(GENRE_FEATURES[item_id]) if g == 1]\n        if genre_indices and GENRE_NAMES:\n            return ', '.join([GENRE_NAMES[i] for i in genre_indices if i < len(GENRE_NAMES)])\n    \n    return \"Unknown\"\n\n\ndef predict_score(model, user_id: int, item_id: int, \n                genre_vector: Optional[np.ndarray] = None,\n                synopsis_embedding: Optional[np.ndarray] = None,\n                device: str = DEVICE) -> float:\n    \"\"\"Predict score for a user-item pair.\"\"\"\n    model.eval()\n    \n    user_tensor = torch.LongTensor([user_id]).to(device)\n    item_tensor = torch.LongTensor([item_id]).to(device)\n    \n    kwargs = {}\n    if genre_vector is not None:\n        kwargs['genre_features'] = torch.FloatTensor([genre_vector]).to(device)\n    if synopsis_embedding is not None:\n        kwargs['synopsis_embeddings'] = torch.FloatTensor([synopsis_embedding]).to(device)\n    \n    with torch.no_grad():\n        logits = model(user_tensor, item_tensor, **kwargs)\n        score = torch.sigmoid(logits).squeeze(-1).item()\n    \n    return score\n\n\ndef recommend(model, user_id: int, k: int = 10,\n             item_genre_features: Optional[np.ndarray] = None,\n             item_synopsis_embeddings: Optional[np.ndarray] = None,\n             seen_items: Optional[List[int]] = None,\n             device: str = DEVICE) -> List[Dict]:\n    \"\"\"Recommend top-K items for a user.\"\"\"\n    model.eval()\n    num_items = model.num_items\n    \n    candidate_items = list(range(num_items))\n    if seen_items is not None:\n        candidate_items = [item for item in candidate_items if item not in seen_items]\n    \n    user_tensor = torch.LongTensor([user_id] * len(candidate_items)).to(device)\n    item_tensor = torch.LongTensor(candidate_items).to(device)\n    \n    kwargs = {}\n    if item_genre_features is not None:\n        kwargs['genre_features'] = torch.FloatTensor(item_genre_features[candidate_items]).to(device)\n    if item_synopsis_embeddings is not None:\n        kwargs['synopsis_embeddings'] = torch.FloatTensor(item_synopsis_embeddings[candidate_items]).to(device)\n    \n    with torch.no_grad():\n        logits = model(user_tensor, item_tensor, **kwargs)\n        scores = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n    \n    top_indices = np.argsort(scores)[::-1][:k]\n    \n    recommendations = []\n    for idx in top_indices:\n        item_id = int(candidate_items[idx])\n        recommendations.append({\n            'item_id': item_id,\n            'score': float(scores[idx]),\n            'rank': len(recommendations) + 1,\n            'title': get_movie_title(item_id, movies_df),\n            'genres': get_movie_genres(item_id, movies_df),\n        })\n    \n    return recommendations\n\n\ndef load_multiple_models(model_paths: Dict[str, str], device: str = DEVICE) -> Dict[str, tuple]:\n    \"\"\"Load multiple models for comparison.\"\"\"\n    loaded = {}\n    for name, path in model_paths.items():\n        try:\n            model_obj, checkpoint = NeuMFPlus.load(path, device=device)\n            model_obj.eval()\n            loaded[name] = (model_obj, checkpoint)\n            print(f\"‚úÖ Loaded: {name}\")\n        except Exception as e:\n            print(f\"‚ùå Failed to load {name}: {e}\")\n    return loaded\n\nprint(\"‚úÖ Helper functions defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Generate Genre Features (Optional)\n\nIf `item_genre_features.npy` is missing, run this cell to generate it from `movies_metadata.csv`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Generate item_genre_features.npy from movies_metadata.csv\n# @markdown Run this cell ONLY if genre features are missing. It will generate the file from your existing metadata.\n\nimport os\nimport pickle\nimport json\nimport ast\nimport numpy as np\nimport pandas as pd\n\ndef parse_genres_from_json(genres_str: str):\n    \"\"\"Parse genres from JSON or Python list string.\"\"\"\n    if pd.isna(genres_str) or genres_str == \"\":\n        return []\n    try:\n        genres = json.loads(genres_str)\n        return [g[\"name\"] for g in genres]\n    except:\n        try:\n            genres = ast.literal_eval(genres_str)\n            return [g[\"name\"] for g in genres]\n        except:\n            return []\n\ndef extract_all_genres(movies_df):\n    \"\"\"Extract all unique genres.\"\"\"\n    all_genres = set()\n    for genres_str in movies_df[\"genres\"].dropna():\n        genres = parse_genres_from_json(genres_str)\n        all_genres.update(genres)\n    return sorted(list(all_genres))\n\n# Paths\ngenre_output_path = os.path.join(DATA_DIR, \"item_genre_features.npy\")\n\nprint(\"=\"*70)\nprint(\"GENERATING GENRE FEATURES FROM MOVIES METADATA\")\nprint(\"=\"*70)\n\n# Load mappings\nprint(f\"\\n[1/5] Loading mappings...\")\nwith open(os.path.join(DATA_DIR, \"mappings.pkl\"), 'rb') as f:\n    mappings = pickle.load(f)\n\nnum_items = mappings['num_items']\nitem_id_map = mappings.get('item_id_map', {})\ngenre_names_from_mapping = mappings.get('genre_names', [])\n\nprint(f\"   Items: {num_items:,}\")\n\n# Load movies metadata\nprint(f\"\\n[2/5] Loading movies metadata...\")\nmovies_df = pd.read_csv(os.path.join(DATASETS_DIR, \"movies_metadata.csv\"), low_memory=False)\nmovies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\nmovies_df = movies_df[movies_df['id'].notna()]\nmovies_df['id'] = movies_df['id'].astype(int)\nprint(f\"   Movies: {len(movies_df):,}\")\n\n# Extract genres\nprint(f\"\\n[3/5] Extracting unique genres...\")\nall_genres = extract_all_genres(movies_df)\nprint(f\"   Genres: {all_genres}\")\n\n# Use genre names from mapping if available\nif genre_names_from_mapping and len(genre_names_from_mapping) == len(all_genres):\n    genre_list = genre_names_from_mapping\nelse:\n    genre_list = all_genres\n\n# Create genre features array\nprint(f\"\\n[4/5] Creating genre features array: ({num_items}, {len(genre_list)})\")\ngenre_features = np.zeros((num_items, len(genre_list)), dtype=np.float32)\n\nitems_matched = 0\ngenre_counts = {g: 0 for g in genre_list}\n\n# Map movies to items and encode genres\nfor _, row in movies_df.iterrows():\n    tmdb_id = row['id']\n    if tmdb_id in item_id_map:\n        item_idx = item_id_map[tmdb_id]\n        genres = parse_genres_from_json(row['genres'])\n        if genres:\n            items_matched += 1\n            for genre in genres:\n                if genre in genre_list:\n                    genre_idx = genre_list.index(genre)\n                    genre_features[item_idx, genre_idx] = 1.0\n                    genre_counts[genre] += 1\n\n# Print statistics\nprint(f\"\\n{'='*70}\")\nprint(\"GENERATION COMPLETE!\")\nprint(f\"{'='*70}\")\nprint(f\"\\nItems matched: {items_matched:,} / {num_items:,} ({items_matched/num_items*100:.1f}%)\")\nprint(f\"\\nGenre distribution:\")\nfor genre, count in sorted(genre_counts.items(), key=lambda x: -x[1]):\n    pct = count / items_matched * 100 if items_matched > 0 else 0\n    print(f\"  {genre:20s}: {count:6,} items ({pct:5.1f}%)\")\n\n# Save\nprint(f\"\\n[5/5] Saving to: {genre_output_path}\")\nnp.save(genre_output_path, genre_features)\n\nprint(f\"\\n‚úÖ Genre features saved!\")\nprint(f\"   Shape: {genre_features.shape}\")\nprint(f\"   Size: {os.path.getsize(genre_output_path) / (1024*1024):.1f} MB\")\n\n# Reload in next cell\nprint(f\"\\n‚ö†Ô∏è  Please RE-RUN the 'Load mappings and features' cell above to load the new genre features!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# @title Define helper functions (FIXED - with reverse mapping)\n\n# Import reverse mapping from loaded data\nreverse_item_map = {v: k for k, v in mappings.get('item_id_map', {}).items()}\n\ndef get_movie_title(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n    \"\"\"Get movie title for internal item ID.\"\"\"\n    if movies_df is None:\n        return f\"Movie {item_id}\"\n    \n    # Convert internal item_id to TMDB ID\n    tmdb_id = reverse_item_map.get(item_id)\n    if tmdb_id is None:\n        return f\"Movie {item_id}\"\n    \n    # Try to get title from movies_df using TMDB ID\n    if tmdb_id in movies_df.index:\n        title = movies_df.loc[tmdb_id, 'title']\n        return title if pd.notna(title) else f\"Movie {item_id}\"\n    \n    return f\"Movie {item_id}\"\n\n\ndef parse_genres(genres_str: str) -> list:\n    \"\"\"Parse genres from JSON string.\"\"\"\n    import json\n    import ast\n    \n    if pd.isna(genres_str) or genres_str == \"\":\n        return []\n    \n    try:\n        genres = json.loads(genres_str)\n        return [g['name'] for g in genres]\n    except:\n        try:\n            genres = ast.literal_eval(genres_str)\n            return [g['name'] for g in genres]\n        except:\n            return []\n\n\ndef get_movie_genres(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n    \"\"\"Get genres for internal item ID.\"\"\"\n    global GENRE_FEATURES, GENRE_NAMES\n    \n    # First try: Use genre features array (most reliable)\n    if GENRE_FEATURES is not None and item_id < len(GENRE_FEATURES):\n        genre_indices = [i for i, g in enumerate(GENRE_FEATURES[item_id]) if g == 1]\n        if genre_indices and GENRE_NAMES:\n            return ', '.join([GENRE_NAMES[i] for i in genre_indices if i < len(GENRE_NAMES)])\n    \n    # Second try: Get from movies_df using TMDB ID mapping\n    if movies_df is not None:\n        tmdb_id = reverse_item_map.get(item_id)\n        if tmdb_id is not None and tmdb_id in movies_df.index:\n            genres_str = movies_df.loc[tmdb_id, 'genres']\n            genres = parse_genres(genres_str)\n            if genres:\n                return ', '.join(genres)\n    \n    return \"Unknown\"\n\n\ndef predict_score(model, user_id: int, item_id: int, \n                genre_vector: Optional[np.ndarray] = None,\n                synopsis_embedding: Optional[np.ndarray] = None,\n                device: str = DEVICE) -> float:\n    \"\"\"Predict score for a user-item pair.\"\"\"\n    model.eval()\n    \n    user_tensor = torch.LongTensor([user_id]).to(device)\n    item_tensor = torch.LongTensor([item_id]).to(device)\n    \n    kwargs = {}\n    if genre_vector is not None:\n        kwargs['genre_features'] = torch.FloatTensor([genre_vector]).to(device)\n    if synopsis_embedding is not None:\n        kwargs['synopsis_embeddings'] = torch.FloatTensor([synopsis_embedding]).to(device)\n    \n    with torch.no_grad():\n        logits = model(user_tensor, item_tensor, **kwargs)\n        score = torch.sigmoid(logits).squeeze(-1).item()\n    \n    return score\n\n\ndef recommend(model, user_id: int, k: int = 10,\n             item_genre_features: Optional[np.ndarray] = None,\n             item_synopsis_embeddings: Optional[np.ndarray] = None,\n             seen_items: Optional[List[int]] = None,\n             device: str = DEVICE) -> List[Dict]:\n    \"\"\"Recommend top-K items for a user.\"\"\"\n    model.eval()\n    num_items = model.num_items\n    \n    candidate_items = list(range(num_items))\n    if seen_items is not None:\n        candidate_items = [item for item in candidate_items if item not in seen_items]\n    \n    user_tensor = torch.LongTensor([user_id] * len(candidate_items)).to(device)\n    item_tensor = torch.LongTensor(candidate_items).to(device)\n    \n    kwargs = {}\n    if item_genre_features is not None:\n        kwargs['genre_features'] = torch.FloatTensor(item_genre_features[candidate_items]).to(device)\n    if item_synopsis_embeddings is not None:\n        kwargs['synopsis_embeddings'] = torch.FloatTensor(item_synopsis_embeddings[candidate_items]).to(device)\n    \n    with torch.no_grad():\n        logits = model(user_tensor, item_tensor, **kwargs)\n        scores = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n    \n    top_indices = np.argsort(scores)[::-1][:k]\n    \n    recommendations = []\n    for idx in top_indices:\n        item_id = int(candidate_items[idx])\n        recommendations.append({\n            'item_id': item_id,\n            'score': float(scores[idx]),\n            'rank': len(recommendations) + 1,\n            'title': get_movie_title(item_id, movies_df),\n            'genres': get_movie_genres(item_id, movies_df),\n        })\n    \n    return recommendations\n\n\ndef load_multiple_models(model_paths: Dict[str, str], device: str = DEVICE) -> Dict[str, tuple]:\n    \"\"\"Load multiple models for comparison.\"\"\"\n    loaded = {}\n    for name, path in model_paths.items():\n        try:\n            model_obj, checkpoint = NeuMFPlus.load(path, device=device)\n            model_obj.eval()\n            loaded[name] = (model_obj, checkpoint)\n            print(f\"‚úÖ Loaded: {name}\")\n        except Exception as e:\n            print(f\"‚ùå Failed to load {name}: {e}\")\n    return loaded\n\nprint(\"‚úÖ Helper functions defined with reverse mapping support!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Get top-K recommendations\n",
    "# @markdown Enter user ID and number of recommendations:\n",
    "\n",
    "user_id_rec = 100  # @param {type:\"integer\"}\n",
    "k_recommendations = 10  # @param {type:\"integer\", min:1, max:50}\n",
    "\n",
    "if user_id_rec >= NUM_USERS:\n",
    "    print(f\"‚ùå Invalid user ID. Must be less than {NUM_USERS}.\")\n",
    "else:\n",
    "    recommendations = recommend(\n",
    "        model, user_id_rec, k=k_recommendations,\n",
    "        item_genre_features=GENRE_FEATURES,\n",
    "        item_synopsis_embeddings=SYNOPSIS_EMBEDDINGS,\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"TOP-{k_recommendations} RECOMMENDATIONS FOR USER {user_id_rec}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6} {'Score':<10} {'Title':<50} {'Genres'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        title = rec['title'][:47] + '...' if len(rec['title']) > 47 else rec['title']\n",
    "        print(f\"{rec['rank']:<6} {rec['score']:.4f}     {title:<50} {rec['genres']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Example: Compare Multiple Users\n",
    "\n",
    "See how different users would rate the same movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Compare predictions for multiple users\n",
    "# @markdown Enter item ID and list of user IDs to compare:\n",
    "\n",
    "item_id_compare = 500  # @param {type:\"integer\"}\n",
    "user_ids_compare = \"0, 50, 100, 500, 1000\"  # @param {type:\"string\"}\n",
    "\n",
    "try:\n",
    "    user_list = [int(u.strip()) for u in user_ids_compare.split(',')]\n",
    "except:\n",
    "    user_list = [0, 50, 100, 500, 1000]\n",
    "\n",
    "if item_id_compare >= NUM_ITEMS:\n",
    "    print(f\"‚ùå Invalid item ID. Must be less than {NUM_ITEMS}.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(f\"USER COMPARISON FOR ITEM: {get_movie_title(item_id_compare, movies_df)}\")\n",
    "    print(f\"Genres: {get_movie_genres(item_id_compare, movies_df)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n{'User ID':<12} {'Score':<10} {'Prediction'}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    genre_vec = GENRE_FEATURES[item_id_compare] if GENRE_FEATURES is not None else None\n",
    "    synopsis_emb = SYNOPSIS_EMBEDDINGS[item_id_compare] if SYNOPSIS_EMBEDDINGS is not None else None\n",
    "    \n",
    "    for user_id in user_list:\n",
    "        if user_id >= NUM_USERS:\n",
    "            print(f\"{user_id:<12} (invalid user)\")\n",
    "            continue\n",
    "        \n",
    "        score = predict_score(model, user_id, item_id_compare, genre_vec, synopsis_emb)\n",
    "        \n",
    "        if score > 0.8:\n",
    "            prediction = \"Will love it!\"\n",
    "        elif score > 0.6:\n",
    "            prediction = \"Will probably like it\"\n",
    "        elif score > 0.4:\n",
    "            prediction = \"Maybe\"\n",
    "        else:\n",
    "            prediction = \"Probably not interested\"\n",
    "        \n",
    "        print(f\"{user_id:<12} {score:.4f}     {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced: Cold-Start Prediction for New Movies\n",
    "\n",
    "Predict how users would rate a completely new movie using only its content features (genres and synopsis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cold-start prediction for a new movie\n",
    "# @markdown Enter movie details for prediction:\n",
    "\n",
    "new_user_id = 100  # @param {type:\"integer\"}\n",
    "new_movie_genres = \"Action,Sci-Fi\"  # @param {type:\"string\"}\n",
    "new_movie_synopsis = \"A group of astronauts discover a mysterious artifact on Mars that changes their understanding of humanity's place in the universe.\"  # @param {type:\"string\"}\n",
    "\n",
    "if new_user_id >= NUM_USERS:\n",
    "    print(f\"‚ùå Invalid user ID. Must be less than {NUM_USERS}.\")\n",
    "else:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    # Load SBERT model for synopsis encoding\n",
    "    print(\"Loading Sentence-BERT model...\")\n",
    "    sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Encode genres\n",
    "    genre_list = [g.strip() for g in new_movie_genres.split(',')]\n",
    "    genre_vector = np.zeros(NUM_GENRES, dtype=np.float32)\n",
    "    \n",
    "    if GENRE_NAMES:\n",
    "        for genre in genre_list:\n",
    "            if genre in GENRE_NAMES:\n",
    "                idx = GENRE_NAMES.index(genre)\n",
    "                genre_vector[idx] = 1.0\n",
    "    \n",
    "    # Encode synopsis\n",
    "    synopsis_embedding = sbert.encode(new_movie_synopsis, show_progress_bar=False)\n",
    "    synopsis_embedding = np.array(synopsis_embedding, dtype=np.float32)\n",
    "    \n",
    "    # Use a placeholder item ID (last item as reference)\n",
    "    placeholder_item_id = NUM_ITEMS - 1\n",
    "    \n",
    "    # Predict\n",
    "    score = predict_score(\n",
    "        model, new_user_id, placeholder_item_id,\n",
    "        genre_vector=genre_vector,\n",
    "        synopsis_embedding=synopsis_embedding\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COLD-START PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nUser ID: {new_user_id}\")\n",
    "    print(f\"\\nNew Movie:\")\n",
    "    print(f\"  Genres: {new_movie_genres}\")\n",
    "    print(f\"  Synopsis: {new_movie_synopsis[:100]}...\")\n",
    "    print(f\"\\n‚úÖ Predicted score: {score:.4f}\")\n",
    "    \n",
    "    if score > 0.7:\n",
    "        print(\"\\nüé¨ This user would likely enjoy this movie!\")\n",
    "    elif score > 0.5:\n",
    "        print(\"\\nüé¨ This user might be interested in this movie.\")\n",
    "    else:\n",
    "        print(\"\\nüé¨ This movie may not be a good fit for this user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Interactive Recommendation Widget\n",
    "\n",
    "Use this interactive widget to explore recommendations for different users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Interactive recommendation widget\n",
    "\n",
    "user_widget = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=NUM_USERS-1,\n",
    "    step=1,\n",
    "    description='User ID:',\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "k_widget = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='Top K:',\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "rec_out = widgets.Output()\n",
    "\n",
    "def update_recommendations(user_id, k):\n",
    "    with rec_out:\n",
    "        rec_out.clear_output()\n",
    "        \n",
    "        recommendations = recommend(\n",
    "            model, user_id, k=k,\n",
    "            item_genre_features=GENRE_FEATURES,\n",
    "            item_synopsis_embeddings=SYNOPSIS_EMBEDDINGS,\n",
    "        )\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\"TOP-{k} RECOMMENDATIONS FOR USER {user_id}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\n{'Rank':<6} {'Score':<10} {'Title':<50} {'Genres'}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            title = rec['title'][:47] + '...' if len(rec['title']) > 47 else rec['title']\n",
    "            print(f\"{rec['rank']:<6} {rec['score']:.4f}     {title:<50} {rec['genres']}\")\n",
    "\n",
    "widgets.interactive(update_recommendations, user_id=user_widget, k=k_widget)\n",
    "\n",
    "display(widgets.VBox([user_widget, k_widget, rec_out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook provides a complete interface for:\n\n1. **Loading trained models** from Google Drive\n2. **Single model selection** - Choose between:\n   - `NeuMF_best.pt` - Baseline (CF only)\n   - `NeuMFPlus_genre_best.pt` - Genre-enhanced\n   - `NeuMFPlus_genre_synopsis_bestt.pt` - Full model (Genre + Synopsis)\n3. **Model comparison** - Compare predictions from different models side-by-side\n4. **Predicting scores** for user-item pairs\n5. **Generating recommendations** for users\n6. **Cold-start predictions** for new movies\n7. **Interactive exploration** of the recommendation system\n\n**Tips:**\n- Use the GPU runtime in Colab for faster inference\n- Adjust `GDRIVE_BASE` if your files are in a different location\n- Ensure all data files (mappings.pkl, features, metadata) are in the correct directories\n- Use the Model Comparison section to understand how content features affect predictions\n\n**Model Selection Guide:**\n- Use **Baseline** for pure collaborative filtering (fastest)\n- Use **Genre Only** when you want genre-aware recommendations\n- Use **Genre + Synopsis** for the best accuracy (slower but most accurate)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}