{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWaL1tBc-Q9"
      },
      "source": [
        "# NCF Movie Recommender - Model Inference on Colab\n",
        "\n",
        "This notebook demonstrates how to use trained NCF/NeuMF+ models for movie recommendations.\n",
        "\n",
        "**Features:**\n",
        "- Load trained models from Google Drive\n",
        "- Generate top-K movie recommendations for users\n",
        "- Predict scores for user-item pairs\n",
        "- Handle cold-start scenarios (new movies)\n",
        "- Display movie titles and genres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMHPmcKc-Q_"
      },
      "source": [
        "## 1. Setup - Mount Google Drive\n",
        "\n",
        "This notebook expects your trained models and data to be in Google Drive.\n",
        "\n",
        "**Required structure in Google Drive:**\n",
        "```\n",
        "MyDrive/\n",
        "â””â”€â”€ NCF-Movie-Recommender/\n",
        "    â”œâ”€â”€ data/                    # Processed data files\n",
        "    â”‚   â”œâ”€â”€ mappings.pkl         # User/item mappings\n",
        "    â”‚   â”œâ”€â”€ item_synopsis_embeddings.npy\n",
        "    â”‚   â””â”€â”€ ...\n",
        "    â”œâ”€â”€ datasets/                # Raw datasets\n",
        "    â”‚   â””â”€â”€ movies_metadata.csv  # Movie titles and info\n",
        "    â””â”€â”€ experiments/\n",
        "        â””â”€â”€ trained_models/      # Trained model checkpoints\n",
        "            â”œâ”€â”€ NeuMFPlus_genre_synopsis_best.pt\n",
        "            â””â”€â”€ ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2Dyp1BvOc-Q_",
        "outputId": "7c13009a-0c40-4b53-a5ca-24c77fe2a09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "# @title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"âœ… Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn7Q1k9Zc-RA"
      },
      "source": [
        "## 2. Configure Paths\n",
        "\n",
        "Update these paths to match your Google Drive structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "fPgkgIBac-RA",
        "outputId": "03fa9e04-7c86-49c4-d215-2ae871ca1c3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Base directory: /content/drive/MyDrive/NCF-Movie-Recommender\n",
            "ðŸ“ Data directory: /content/drive/MyDrive/NCF-Movie-Recommender/data\n",
            "ðŸ“ Datasets directory: /content/drive/MyDrive/NCF-Movie-Recommender/datasets\n",
            "ðŸ“ Models directory: /content/drive/MyDrive/NCF-Movie-Recommender/experiments/trained_models\n",
            "\n",
            "âœ… Data directory found! Files: 14\n",
            "âœ… Datasets directory found! Files: 4\n",
            "âœ… Models directory found! Checkpoints: 5\n",
            "\n",
            "Available models:\n",
            "  â€¢ NeuMFPlus_best.pt\n",
            "  â€¢ NeuMFPlus_best_best.pt\n",
            "  â€¢ NeuMFPlus_genre_best.pt\n",
            "  â€¢ NeuMFPlus_genre_synopsis_bestt.pt\n",
            "  â€¢ NeuMF_best.pt\n"
          ]
        }
      ],
      "source": [
        "# @title Configure paths\n",
        "import os\n",
        "\n",
        "# @markdown **Base path for NCF-Movie-Recommender project:**\n",
        "GDRIVE_BASE = \"/content/drive/MyDrive/NCF-Movie-Recommender\"  # @param {type:\"string\"}\n",
        "\n",
        "# Paths relative to your Google Drive base\n",
        "DATA_DIR = os.path.join(GDRIVE_BASE, \"data\")\n",
        "DATASETS_DIR = os.path.join(GDRIVE_BASE, \"datasets\")\n",
        "MODELS_DIR = os.path.join(GDRIVE_BASE, \"experiments\", \"trained_models\")\n",
        "\n",
        "print(f\"ðŸ“ Base directory: {GDRIVE_BASE}\")\n",
        "print(f\"ðŸ“ Data directory: {DATA_DIR}\")\n",
        "print(f\"ðŸ“ Datasets directory: {DATASETS_DIR}\")\n",
        "print(f\"ðŸ“ Models directory: {MODELS_DIR}\")\n",
        "\n",
        "# Verify directories exist\n",
        "if os.path.exists(DATA_DIR):\n",
        "    data_files = os.listdir(DATA_DIR)\n",
        "    print(f\"\\nâœ… Data directory found! Files: {len(data_files)}\")\n",
        "else:\n",
        "    print(f\"\\nâŒ Data directory not found: {DATA_DIR}\")\n",
        "\n",
        "if os.path.exists(DATASETS_DIR):\n",
        "    datasets_files = os.listdir(DATASETS_DIR)\n",
        "    print(f\"âœ… Datasets directory found! Files: {len(datasets_files)}\")\n",
        "else:\n",
        "    print(f\"âŒ Datasets directory not found: {DATASETS_DIR}\")\n",
        "\n",
        "if os.path.exists(MODELS_DIR):\n",
        "    model_files = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n",
        "    print(f\"âœ… Models directory found! Checkpoints: {len(model_files)}\")\n",
        "    if model_files:\n",
        "        print(\"\\nAvailable models:\")\n",
        "        for f in sorted(model_files):\n",
        "            print(f\"  â€¢ {f}\")\n",
        "else:\n",
        "    print(f\"\\nâŒ Models directory not found: {MODELS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFAzrgr1c-RB"
      },
      "source": [
        "## 3. Install Dependencies\n",
        "\n",
        "Install required Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ItX2Zznmc-RB",
        "outputId": "2fee9a33-b5e2-4d2c-bbe3-8826eb0699f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dependencies installed!\n",
            "   PyTorch: 2.9.0+cpu\n",
            "   CUDA available: False\n",
            "   Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies\n",
        "!pip install -q torch numpy pandas sentence-transformers tqdm\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "print(\"âœ… Dependencies installed!\")\n",
        "print(f\"   PyTorch: {torch.__version__}\")\n",
        "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Set device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"   Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxnPO66Oc-RB"
      },
      "source": [
        "## 4. Define Model Architecture\n",
        "\n",
        "This section defines the NeuMF+ model architecture to match your trained checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "xzP7895Dc-RB",
        "outputId": "6acb389a-712c-4f3c-9b75-981d55ee0613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model architecture defined!\n"
          ]
        }
      ],
      "source": [
        "# @title Define NeuMF+ Model (matching trained checkpoints)\n",
        "import torch.nn as nn\n",
        "\n",
        "class ContentEncoder(nn.Module):\n",
        "    \"\"\"Encode content features (genre + synopsis) into embeddings.\"\"\"\n",
        "\n",
        "    def __init__(self, num_genres: int, genre_embed_dim: int = 64,\n",
        "                 synopsis_embed_dim: int = 384, content_embed_dim: int = 256,\n",
        "                 dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.genre_encoder = nn.Sequential(\n",
        "            nn.Linear(num_genres, genre_embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.synopsis_projection = nn.Sequential(\n",
        "            nn.Linear(synopsis_embed_dim, synopsis_embed_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        combined_dim = genre_embed_dim + synopsis_embed_dim // 2\n",
        "        self.content_encoder = nn.Sequential(\n",
        "            nn.Linear(combined_dim, content_embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, genre_features, synopsis_embeddings):\n",
        "        genre_embed = self.genre_encoder(genre_features)\n",
        "        synopsis_embed = self.synopsis_projection(synopsis_embeddings)\n",
        "        combined = torch.cat([genre_embed, synopsis_embed], dim=-1)\n",
        "        return self.content_encoder(combined)\n",
        "\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    \"\"\"Gated fusion for CF and content embeddings.\"\"\"\n",
        "\n",
        "    def __init__(self, cf_dim: int, content_dim: int, hidden_dim: int = 64, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gate_network = nn.Sequential(\n",
        "            nn.Linear(cf_dim + content_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, cf_embed, content_embed):\n",
        "        combined = torch.cat([cf_embed, content_embed], dim=-1)\n",
        "        gate = self.gate_network(combined)\n",
        "\n",
        "        if cf_embed.shape[-1] != content_embed.shape[-1]:\n",
        "            if cf_embed.shape[-1] > content_embed.shape[-1]:\n",
        "                target_dim = cf_embed.shape[-1]\n",
        "                if not hasattr(self, '_content_proj'):\n",
        "                    self._content_proj = nn.Linear(content_embed.shape[-1], target_dim).to(cf_embed.device)\n",
        "                content_embed = self._content_proj(content_embed)\n",
        "            else:\n",
        "                target_dim = content_embed.shape[-1]\n",
        "                if not hasattr(self, '_cf_proj'):\n",
        "                    self._cf_proj = nn.Linear(cf_embed.shape[-1], target_dim).to(cf_embed.device)\n",
        "                cf_embed = self._cf_proj(cf_embed)\n",
        "\n",
        "        fused = gate * cf_embed + (1 - gate) * content_embed\n",
        "        return fused, gate\n",
        "\n",
        "\n",
        "class NeuMFPlus(nn.Module):\n",
        "    \"\"\"NeuMF+ with Genre, Synopsis, and Gated Fusion.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_users: int,\n",
        "        num_items: int,\n",
        "        num_genres: int,\n",
        "        # CF (NeuMF) parameters\n",
        "        embedding_dim: int = 32,\n",
        "        gmf_hidden_dim: int = 8,\n",
        "        mlp_hidden_dims: list = None,\n",
        "        mlp_dropout: float = 0.2,\n",
        "        fusion_dim: int = 32,\n",
        "        # Content encoder parameters\n",
        "        genre_embed_dim: int = 64,\n",
        "        synopsis_embed_dim: int = 384,\n",
        "        content_embed_dim: int = 256,\n",
        "        content_encoder_dropout: float = 0.1,\n",
        "        # Gated fusion parameters\n",
        "        gated_fusion_hidden_dim: int = 64,\n",
        "        gated_fusion_dropout: float = 0.1,\n",
        "        # Output parameters\n",
        "        output_hidden_dim: int = 64,\n",
        "        output_dropout: float = 0.2,\n",
        "        # Ablation study flags\n",
        "        use_genre: bool = True,\n",
        "        use_synopsis: bool = True,\n",
        "        use_gated_fusion: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.num_genres = num_genres\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.use_genre = use_genre\n",
        "        self.use_synopsis = use_synopsis\n",
        "        self.use_gated_fusion = use_gated_fusion\n",
        "        self.synopsis_embed_dim = synopsis_embed_dim\n",
        "        self.content_embed_dim = content_embed_dim\n",
        "\n",
        "        # Calculate content dimensions\n",
        "        if use_genre and use_synopsis:\n",
        "            self.content_encoder = ContentEncoder(\n",
        "                num_genres=num_genres,\n",
        "                genre_embed_dim=genre_embed_dim,\n",
        "                synopsis_embed_dim=synopsis_embed_dim,\n",
        "                content_embed_dim=content_embed_dim,\n",
        "                dropout=content_encoder_dropout,\n",
        "            )\n",
        "            actual_content_dim = content_embed_dim\n",
        "        elif use_genre:\n",
        "            self.genre_encoder = nn.Sequential(\n",
        "                nn.Linear(num_genres, genre_embed_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(content_encoder_dropout),\n",
        "            )\n",
        "            actual_content_dim = genre_embed_dim\n",
        "        elif use_synopsis:\n",
        "            self.synopsis_projection = nn.Sequential(\n",
        "                nn.Linear(synopsis_embed_dim, synopsis_embed_dim // 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(content_encoder_dropout),\n",
        "            )\n",
        "            actual_content_dim = synopsis_embed_dim // 2\n",
        "        else:\n",
        "            actual_content_dim = 0\n",
        "\n",
        "        # CF (NeuMF) branch - separate embeddings for GMF and MLP\n",
        "        self.gmf_user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.gmf_item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "        self.mlp_user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.mlp_item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        # Initialize embeddings\n",
        "        nn.init.xavier_uniform_(self.gmf_user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.gmf_item_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.mlp_user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.mlp_item_embedding.weight)\n",
        "\n",
        "        # GMF branch\n",
        "        self.gmf_fc = nn.Linear(embedding_dim, gmf_hidden_dim)\n",
        "\n",
        "        # MLP branch\n",
        "        mlp_hidden_dims = mlp_hidden_dims or [128, 64, 32]\n",
        "        mlp_input_dim = 2 * embedding_dim\n",
        "        self.mlp_layers = nn.ModuleList()\n",
        "        self.mlp_dropout_layers = nn.ModuleList()\n",
        "\n",
        "        prev_dim = mlp_input_dim\n",
        "        for hidden_dim in mlp_hidden_dims:\n",
        "            self.mlp_layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            self.mlp_dropout_layers.append(nn.Dropout(mlp_dropout))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        # NeuMF fusion layer\n",
        "        self.neumf_fusion_fc = nn.Linear(gmf_hidden_dim + prev_dim, fusion_dim)\n",
        "        self.neumf_fusion_dropout = nn.Dropout(0.1)\n",
        "        self.cf_output_dim = fusion_dim\n",
        "\n",
        "        # Content fusion\n",
        "        if actual_content_dim > 0:\n",
        "            if use_gated_fusion:\n",
        "                self.gated_fusion = GatedFusion(\n",
        "                    cf_dim=self.cf_output_dim,\n",
        "                    content_dim=actual_content_dim,\n",
        "                    hidden_dim=gated_fusion_hidden_dim,\n",
        "                    dropout=gated_fusion_dropout,\n",
        "                )\n",
        "                self.final_input_dim = max(self.cf_output_dim, actual_content_dim)\n",
        "            else:\n",
        "                self.final_input_dim = self.cf_output_dim + actual_content_dim\n",
        "        else:\n",
        "            self.final_input_dim = self.cf_output_dim\n",
        "\n",
        "        # Output layers\n",
        "        self.output_fc = nn.Sequential(\n",
        "            nn.Linear(self.final_input_dim, output_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(output_dropout),\n",
        "            nn.Linear(output_hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self) -> None:\n",
        "        \"\"\"Initialize weights.\"\"\"\n",
        "        if self.use_genre and not self.use_synopsis:\n",
        "            if hasattr(self, 'genre_encoder'):\n",
        "                for module in self.genre_encoder:\n",
        "                    if isinstance(module, nn.Linear):\n",
        "                        nn.init.xavier_uniform_(module.weight)\n",
        "                        if module.bias is not None:\n",
        "                            nn.init.zeros_(module.bias)\n",
        "\n",
        "        if self.use_synopsis and not self.use_genre:\n",
        "            if hasattr(self, 'synopsis_projection'):\n",
        "                for module in self.synopsis_projection:\n",
        "                    if isinstance(module, nn.Linear):\n",
        "                        nn.init.xavier_uniform_(module.weight)\n",
        "                        if module.bias is not None:\n",
        "                            nn.init.zeros_(module.bias)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.gmf_fc.weight)\n",
        "        nn.init.zeros_(self.gmf_fc.bias)\n",
        "\n",
        "        for layer in self.mlp_layers:\n",
        "            nn.init.xavier_uniform_(layer.weight)\n",
        "            nn.init.zeros_(layer.bias)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.neumf_fusion_fc.weight)\n",
        "        nn.init.zeros_(self.neumf_fusion_fc.bias)\n",
        "\n",
        "        for module in self.output_fc:\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.xavier_uniform_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        user_ids: torch.Tensor,\n",
        "        item_ids: torch.Tensor,\n",
        "        genre_features: torch.Tensor = None,\n",
        "        synopsis_embeddings: torch.Tensor = None,\n",
        "        return_gate: bool = False,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Forward pass of NeuMF+.\"\"\"\n",
        "        # GMF\n",
        "        gmf_user_embed = self.gmf_user_embedding(user_ids)\n",
        "        gmf_item_embed = self.gmf_item_embedding(item_ids)\n",
        "        gmf_output = gmf_user_embed * gmf_item_embed\n",
        "        gmf_hidden = self.gmf_fc(gmf_output)\n",
        "\n",
        "        # MLP\n",
        "        mlp_user_embed = self.mlp_user_embedding(user_ids)\n",
        "        mlp_item_embed = self.mlp_item_embedding(item_ids)\n",
        "        mlp_concat = torch.cat([mlp_user_embed, mlp_item_embed], dim=-1)\n",
        "\n",
        "        x = mlp_concat\n",
        "        for layer, dropout in zip(self.mlp_layers, self.mlp_dropout_layers):\n",
        "            x = layer(x)\n",
        "            x = torch.relu(x)\n",
        "            x = dropout(x)\n",
        "\n",
        "        mlp_hidden = x\n",
        "\n",
        "        # NeuMF fusion\n",
        "        neumf_input = torch.cat([gmf_hidden, mlp_hidden], dim=-1)\n",
        "        cf_embed = self.neumf_fusion_fc(neumf_input)\n",
        "        cf_embed = torch.relu(cf_embed)\n",
        "        cf_embed = self.neumf_fusion_dropout(cf_embed)\n",
        "\n",
        "        # Content Branch\n",
        "        content_embed = None\n",
        "        if self.use_genre and self.use_synopsis:\n",
        "            if genre_features is None or synopsis_embeddings is None:\n",
        "                batch_size = user_ids.size(0)\n",
        "                device = user_ids.device\n",
        "                if genre_features is None:\n",
        "                    genre_features = torch.zeros(batch_size, self.num_genres, device=device)\n",
        "                if synopsis_embeddings is None:\n",
        "                    synopsis_embeddings = torch.zeros(batch_size, self.synopsis_embed_dim, device=device)\n",
        "            content_embed = self.content_encoder(genre_features, synopsis_embeddings)\n",
        "        elif self.use_genre:\n",
        "            if genre_features is None:\n",
        "                batch_size = user_ids.size(0)\n",
        "                device = user_ids.device\n",
        "                genre_features = torch.zeros(batch_size, self.num_genres, device=device)\n",
        "            content_embed = self.genre_encoder(genre_features)\n",
        "        elif self.use_synopsis:\n",
        "            if synopsis_embeddings is None:\n",
        "                batch_size = user_ids.size(0)\n",
        "                device = user_ids.device\n",
        "                synopsis_embeddings = torch.zeros(batch_size, self.synopsis_embed_dim, device=device)\n",
        "            content_embed = self.synopsis_projection(synopsis_embeddings)\n",
        "\n",
        "        # Fusion\n",
        "        if content_embed is not None:\n",
        "            if self.use_gated_fusion:\n",
        "                final_embed, gate = self.gated_fusion(cf_embed, content_embed)\n",
        "            else:\n",
        "                final_embed = torch.cat([cf_embed, content_embed], dim=-1)\n",
        "                gate = None\n",
        "        else:\n",
        "            final_embed = cf_embed\n",
        "            gate = None\n",
        "\n",
        "        # Output\n",
        "        output = self.output_fc(final_embed)\n",
        "\n",
        "        if return_gate:\n",
        "            return output, gate\n",
        "        return output\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, checkpoint_path: str, device: str = 'cuda'):\n",
        "        \"\"\"Load model from checkpoint.\"\"\"\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "        config = checkpoint['model_config']\n",
        "\n",
        "        model = cls(\n",
        "            num_users=config['num_users'],\n",
        "            num_items=config['num_items'],\n",
        "            num_genres=config['num_genres'],\n",
        "            use_genre=config['use_genre'],\n",
        "            use_synopsis=config['use_synopsis'],\n",
        "            use_gated_fusion=config['use_gated_fusion'],\n",
        "        )\n",
        "\n",
        "        # Load state_dict with strict=False to handle version mismatches\n",
        "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "        model = model.to(device)\n",
        "\n",
        "        return model, checkpoint\n",
        "\n",
        "print(\"âœ… Model architecture defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0BEaiasc-RC"
      },
      "source": [
        "## 5. Load Data and Mappings\n",
        "\n",
        "Load the processed data files including mappings, genre features, and movie metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ozAZ3pgBc-RD",
        "outputId": "5217f9c4-6547-48b1-a862-d773827033e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Mappings loaded!\n",
            "   Users: 256,107\n",
            "   Items: 27,127\n",
            "   Genres: 20\n",
            "\n",
            "âœ… Genre features loaded: (27127, 20)\n",
            "âœ… Synopsis embeddings loaded: (27127, 384)\n",
            "\n",
            "âœ… Movie metadata loaded: 45,463 movies\n",
            "\n",
            "======================================================================\n",
            "DATA LOADING SUMMARY\n",
            "======================================================================\n",
            "Genre features available: âœ… Yes\n",
            "Synopsis embeddings available: âœ… Yes\n",
            "Movie metadata available: âœ… Yes\n"
          ]
        }
      ],
      "source": [
        "# @title Load mappings and features\n",
        "\n",
        "# Load mappings\n",
        "mappings_path = os.path.join(DATA_DIR, \"mappings.pkl\")\n",
        "with open(mappings_path, 'rb') as f:\n",
        "    mappings = pickle.load(f)\n",
        "\n",
        "NUM_USERS = mappings['num_users']\n",
        "NUM_ITEMS = mappings['num_items']\n",
        "NUM_GENRES = mappings['num_genres']\n",
        "GENRE_NAMES = mappings.get('genre_names', [])\n",
        "\n",
        "print(f\"âœ… Mappings loaded!\")\n",
        "print(f\"   Users: {NUM_USERS:,}\")\n",
        "print(f\"   Items: {NUM_ITEMS:,}\")\n",
        "print(f\"   Genres: {NUM_GENRES}\")\n",
        "if GENRE_NAMES:\n",
        "    print(f\"   Genre names: {GENRE_NAMES}\")\n",
        "\n",
        "# Load genre features (if available)\n",
        "# Note: This file may not exist - genre features can be generated from movies_metadata.csv\n",
        "genre_path = os.path.join(DATA_DIR, \"item_genre_features.npy\")\n",
        "if os.path.exists(genre_path):\n",
        "    GENRE_FEATURES = np.load(genre_path)\n",
        "    print(f\"\\nâœ… Genre features loaded: {GENRE_FEATURES.shape}\")\n",
        "else:\n",
        "    GENRE_FEATURES = None\n",
        "    print(f\"\\nâš ï¸  Genre features not found: {genre_path}\")\n",
        "    print(f\"   Models that require genre features will use zero vectors.\")\n",
        "\n",
        "# Load synopsis embeddings\n",
        "# Note: File uses plural \"embeddings\"\n",
        "synopsis_path = os.path.join(DATA_DIR, \"item_synopsis_embeddings.npy\")\n",
        "if os.path.exists(synopsis_path):\n",
        "    SYNOPSIS_EMBEDDINGS = np.load(synopsis_path)\n",
        "    print(f\"âœ… Synopsis embeddings loaded: {SYNOPSIS_EMBEDDINGS.shape}\")\n",
        "else:\n",
        "    SYNOPSIS_EMBEDDINGS = None\n",
        "    print(f\"âš ï¸  Synopsis embeddings not found: {synopsis_path}\")\n",
        "\n",
        "# Load movie metadata for display (from datasets directory)\n",
        "metadata_path = os.path.join(DATASETS_DIR, \"movies_metadata.csv\")\n",
        "if os.path.exists(metadata_path):\n",
        "    movies_df = pd.read_csv(metadata_path, low_memory=False)\n",
        "    # Filter for valid IDs\n",
        "    movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
        "    movies_df = movies_df[movies_df['id'].notna()]\n",
        "    movies_df['id'] = movies_df['id'].astype(int)\n",
        "    movies_df = movies_df.set_index('id')\n",
        "    print(f\"\\nâœ… Movie metadata loaded: {len(movies_df):,} movies\")\n",
        "else:\n",
        "    movies_df = None\n",
        "    print(f\"\\nâš ï¸  Movie metadata not found: {metadata_path}\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA LOADING SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Genre features available: {'âœ… Yes' if GENRE_FEATURES is not None else 'âŒ No'}\")\n",
        "print(f\"Synopsis embeddings available: {'âœ… Yes' if SYNOPSIS_EMBEDDINGS is not None else 'âŒ No'}\")\n",
        "print(f\"Movie metadata available: {'âœ… Yes' if movies_df is not None else 'âŒ No'}\")\n",
        "\n",
        "if GENRE_FEATURES is None:\n",
        "    print(\"\\nâš ï¸  NOTE: Genre features file (item_genre_features.npy) not found.\")\n",
        "    print(\"   If you're using a model that requires genre features,\")\n",
        "    print(\"   the model will automatically use zero vectors for missing features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5l6zghc-RD"
      },
      "source": [
        "## 6. Load Trained Model\n",
        "\n",
        "Select and load one of your trained models.\n",
        "\n",
        "**Available Models:**\n",
        "| Model | Description | Features |\n",
        "|-------|-------------|----------|\n",
        "| `NeuMF_best.pt` | Baseline | Collaborative Filtering only |\n",
        "| `NeuMFPlus_genre_best.pt` | Genre-enhanced | CF + Genre features |\n",
        "| `NeuMFPlus_genre_synopsis_bestt.pt` | Full model | CF + Genre + Synopsis |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Y_Fec-bqc-RD",
        "outputId": "923d37ab-98b2-4a61-86be-7266f19a7b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "7b6ca5cdc5af4840a14b88c1027c7aa7",
            "d8aeaaabd31b4ac98942974ce084aca5",
            "088e656a02184ea98a614b8781e06c17",
            "ad0dfedaed944b9d964de90a4d9a08dc",
            "471883c16b8a47ea904c54bb23dcb42f",
            "b7639eed51b44bfc9af0c62a4429636a",
            "90d6164ae7fc4ec7a23d4e732eb8ea00",
            "0885896f1b964db297043f3d80226284",
            "95f2b8d0f25c43f8bdc9a068d61f2e63",
            "656896b9d519485ea2d40de8327ff9d4"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Select model:', options=(('NeuMFPlus_best.pt  (NeuMFPlus_best.pt)', 'NeuMFPlus_best.pt')â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b6ca5cdc5af4840a14b88c1027c7aa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad0dfedaed944b9d964de90a4d9a08dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Load Model', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7639eed51b44bfc9af0c62a4429636a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95f2b8d0f25c43f8bdc9a068d61f2e63"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Load trained model\n",
        "# @markdown Select the model checkpoint to load:\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Get available models\n",
        "available_models = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n",
        "\n",
        "# Model descriptions\n",
        "MODEL_INFO = {\n",
        "    'NeuMF_best.pt': {\n",
        "        'name': 'NeuMF (Baseline)',\n",
        "        'description': 'Collaborative Filtering only - no content features',\n",
        "        'features': 'User-Item interactions only'\n",
        "    },\n",
        "    'NeuMFPlus_genre_best.pt': {\n",
        "        'name': 'NeuMF+ (Genre)',\n",
        "        'description': 'CF + Genre features',\n",
        "        'features': 'User-Item + Movie genres'\n",
        "    },\n",
        "    'NeuMFPlus_genre_synopsis_bestt.pt': {\n",
        "        'name': 'NeuMF+ (Genre + Synopsis)',\n",
        "        'description': 'CF + Genre + Synopsis features (Full Model)',\n",
        "        'features': 'User-Item + Genres + Movie synopsis'\n",
        "    }\n",
        "}\n",
        "\n",
        "if not available_models:\n",
        "    print(f\"âŒ No models found in {MODELS_DIR}\")\n",
        "else:\n",
        "    # Create dropdown with model descriptions\n",
        "    model_options = [(f\"{m}  ({MODEL_INFO.get(m, {}).get('name', m)})\", m) for m in sorted(available_models)]\n",
        "\n",
        "    model_dropdown = widgets.Dropdown(\n",
        "        options=model_options,\n",
        "        description='Select model:',\n",
        "        style={'description_width': 'initial'},\n",
        "    )\n",
        "    display(model_dropdown)\n",
        "\n",
        "    # Model info display\n",
        "    info_out = widgets.Output()\n",
        "    display(info_out)\n",
        "\n",
        "    def show_model_info(change):\n",
        "        with info_out:\n",
        "            info_out.clear_output()\n",
        "            model_name = change['new']\n",
        "            info = MODEL_INFO.get(model_name, {})\n",
        "            if info:\n",
        "                print(f\"ðŸ“‹ {info.get('name', model_name)}\")\n",
        "                print(f\"   {info.get('description', '')}\")\n",
        "                print(f\"   Features: {info.get('features', 'N/A')}\")\n",
        "\n",
        "    model_dropdown.observe(show_model_info, names='value')\n",
        "    # Show initial info\n",
        "    show_model_info({'new': model_dropdown.value})\n",
        "\n",
        "    # Load button\n",
        "    load_btn = widgets.Button(description='Load Model', button_style='primary')\n",
        "    display(load_btn)\n",
        "\n",
        "    # Output area\n",
        "    out = widgets.Output()\n",
        "    display(out)\n",
        "\n",
        "    def load_model(b):\n",
        "        with out:\n",
        "            out.clear_output()\n",
        "            model_name = model_dropdown.value\n",
        "            checkpoint_path = os.path.join(MODELS_DIR, model_name)\n",
        "\n",
        "            print(f\"Loading model from: {model_name}\")\n",
        "            print(f\"Path: {checkpoint_path}\")\n",
        "\n",
        "            global model, checkpoint, model_config\n",
        "            model, checkpoint = NeuMFPlus.load(checkpoint_path, device=DEVICE)\n",
        "            model.eval()\n",
        "            model_config = checkpoint['model_config']\n",
        "\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"MODEL CONFIGURATION\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"use_genre: {model_config.get('use_genre')}\")\n",
        "            print(f\"use_synopsis: {model_config.get('use_synopsis')}\")\n",
        "            print(f\"use_gated_fusion: {model_config.get('use_gated_fusion')}\")\n",
        "            print(f\"\\nParameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "            if 'metrics' in checkpoint:\n",
        "                print(\"\\nValidation Metrics:\")\n",
        "                for k, v in checkpoint['metrics'].items():\n",
        "                    if isinstance(v, (int, float)):\n",
        "                        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "            # Show what features are needed\n",
        "            print(\"\\n\" + \"-\"*70)\n",
        "            print(\"REQUIRED FEATURES FOR INFERENCE:\")\n",
        "            if model_config.get('use_genre'):\n",
        "                print(\"  âœ… Genre features (item_genre_features.npy)\")\n",
        "            else:\n",
        "                print(\"  âŒ Genre features NOT needed\")\n",
        "            if model_config.get('use_synopsis'):\n",
        "                print(\"  âœ… Synopsis embeddings (item_synopsis_embeddings.npy)\")\n",
        "            else:\n",
        "                print(\"  âŒ Synopsis embeddings NOT needed\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "            print(\"\\nâœ… Model loaded successfully!\")\n",
        "\n",
        "    load_btn.on_click(load_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00s9WlKdc-RE"
      },
      "source": [
        "## 7. Helper Functions\n",
        "\n",
        "Define helper functions for prediction and recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "NocOk-Exc-RE",
        "outputId": "89a8821b-ee7e-4520-c317-144d7bb5bd10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Helper functions defined!\n"
          ]
        }
      ],
      "source": [
        "# @title Define helper functions\n",
        "\n",
        "def get_movie_title(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
        "    \"\"\"Get movie title for item ID.\"\"\"\n",
        "    if movies_df is None:\n",
        "        return f\"Movie {item_id}\"\n",
        "\n",
        "    # Try to get title from movies_df\n",
        "    if item_id in movies_df.index:\n",
        "        title = movies_df.loc[item_id, 'title']\n",
        "        return title if pd.notna(title) else f\"Movie {item_id}\"\n",
        "\n",
        "    return f\"Movie {item_id}\"\n",
        "\n",
        "\n",
        "def parse_genres(genres_str: str) -> list:\n",
        "    \"\"\"Parse genres from JSON string.\"\"\"\n",
        "    import json\n",
        "    import ast\n",
        "\n",
        "    if pd.isna(genres_str) or genres_str == \"\":\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        genres = json.loads(genres_str)\n",
        "        return [g['name'] for g in genres]\n",
        "    except:\n",
        "        try:\n",
        "            genres = ast.literal_eval(genres_str)\n",
        "            return [g['name'] for g in genres]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "\n",
        "def get_movie_genres(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
        "    \"\"\"Get genres for item ID.\"\"\"\n",
        "    if movies_df is None or GENRE_FEATURES is None:\n",
        "        return \"Unknown\"\n",
        "\n",
        "    if item_id in movies_df.index:\n",
        "        genres_str = movies_df.loc[item_id, 'genres']\n",
        "        genres = parse_genres(genres_str)\n",
        "        return ', '.join(genres) if genres else \"Unknown\"\n",
        "\n",
        "    # Use genre features if available\n",
        "    if item_id < len(GENRE_FEATURES):\n",
        "        genre_indices = [i for i, g in enumerate(GENRE_FEATURES[item_id]) if g == 1]\n",
        "        if genre_indices and GENRE_NAMES:\n",
        "            return ', '.join([GENRE_NAMES[i] for i in genre_indices if i < len(GENRE_NAMES)])\n",
        "\n",
        "    return \"Unknown\"\n",
        "\n",
        "\n",
        "def predict_score(model, user_id: int, item_id: int,\n",
        "                genre_vector: Optional[np.ndarray] = None,\n",
        "                synopsis_embedding: Optional[np.ndarray] = None,\n",
        "                device: str = DEVICE) -> float:\n",
        "    \"\"\"Predict score for a user-item pair.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    user_tensor = torch.LongTensor([user_id]).to(device)\n",
        "    item_tensor = torch.LongTensor([item_id]).to(device)\n",
        "\n",
        "    kwargs = {}\n",
        "    if genre_vector is not None:\n",
        "        kwargs['genre_features'] = torch.FloatTensor([genre_vector]).to(device)\n",
        "    if synopsis_embedding is not None:\n",
        "        kwargs['synopsis_embeddings'] = torch.FloatTensor([synopsis_embedding]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(user_tensor, item_tensor, **kwargs)\n",
        "        score = torch.sigmoid(logits).squeeze(-1).item()\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def recommend(model, user_id: int, k: int = 10,\n",
        "             item_genre_features: Optional[np.ndarray] = None,\n",
        "             item_synopsis_embeddings: Optional[np.ndarray] = None,\n",
        "             seen_items: Optional[List[int]] = None,\n",
        "             device: str = DEVICE) -> List[Dict]:\n",
        "    \"\"\"Recommend top-K items for a user.\"\"\"\n",
        "    model.eval()\n",
        "    num_items = model.num_items\n",
        "\n",
        "    candidate_items = list(range(num_items))\n",
        "    if seen_items is not None:\n",
        "        candidate_items = [item for item in candidate_items if item not in seen_items]\n",
        "\n",
        "    user_tensor = torch.LongTensor([user_id] * len(candidate_items)).to(device)\n",
        "    item_tensor = torch.LongTensor(candidate_items).to(device)\n",
        "\n",
        "    kwargs = {}\n",
        "    if item_genre_features is not None:\n",
        "        kwargs['genre_features'] = torch.FloatTensor(item_genre_features[candidate_items]).to(device)\n",
        "    if item_synopsis_embeddings is not None:\n",
        "        kwargs['synopsis_embeddings'] = torch.FloatTensor(item_synopsis_embeddings[candidate_items]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(user_tensor, item_tensor, **kwargs)\n",
        "        scores = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
        "\n",
        "    top_indices = np.argsort(scores)[::-1][:k]\n",
        "\n",
        "    recommendations = []\n",
        "    for idx in top_indices:\n",
        "        item_id = int(candidate_items[idx])\n",
        "        recommendations.append({\n",
        "            'item_id': item_id,\n",
        "            'score': float(scores[idx]),\n",
        "            'rank': len(recommendations) + 1,\n",
        "            'title': get_movie_title(item_id, movies_df),\n",
        "            'genres': get_movie_genres(item_id, movies_df),\n",
        "        })\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "def load_multiple_models(model_paths: Dict[str, str], device: str = DEVICE) -> Dict[str, tuple]:\n",
        "    \"\"\"Load multiple models for comparison.\"\"\"\n",
        "    loaded = {}\n",
        "    for name, path in model_paths.items():\n",
        "        try:\n",
        "            model_obj, checkpoint = NeuMFPlus.load(path, device=device)\n",
        "            model_obj.eval()\n",
        "            loaded[name] = (model_obj, checkpoint)\n",
        "            print(f\"âœ… Loaded: {name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load {name}: {e}\")\n",
        "    return loaded\n",
        "\n",
        "print(\"âœ… Helper functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQeVJOUIc-RE"
      },
      "source": [
        "## 7. Generate Genre Features (Optional)\n",
        "\n",
        "If `item_genre_features.npy` is missing, run this cell to generate it from `movies_metadata.csv`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define helper functions (FIXED - with reverse mapping)\n",
        "\n",
        "# Import reverse mapping from loaded data\n",
        "reverse_item_map = {v: k for k, v in mappings.get('item_id_map', {}).items()}\n",
        "\n",
        "def get_movie_title(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
        "    \"\"\"Get movie title for internal item ID.\"\"\"\n",
        "    if movies_df is None:\n",
        "        return f\"Movie {item_id}\"\n",
        "\n",
        "    # Convert internal item_id to TMDB ID\n",
        "    tmdb_id = reverse_item_map.get(item_id)\n",
        "    if tmdb_id is None:\n",
        "        return f\"Movie {item_id}\"\n",
        "\n",
        "    # Try to get title from movies_df using TMDB ID\n",
        "    if tmdb_id in movies_df.index:\n",
        "        title = movies_df.loc[tmdb_id, 'title']\n",
        "        return title if pd.notna(title) else f\"Movie {item_id}\"\n",
        "\n",
        "    return f\"Movie {item_id}\"\n",
        "\n",
        "\n",
        "def parse_genres(genres_str: str) -> list:\n",
        "    \"\"\"Parse genres from JSON string.\"\"\"\n",
        "    import json\n",
        "    import ast\n",
        "\n",
        "    if pd.isna(genres_str) or genres_str == \"\":\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        genres = json.loads(genres_str)\n",
        "        return [g['name'] for g in genres]\n",
        "    except:\n",
        "        try:\n",
        "            genres = ast.literal_eval(genres_str)\n",
        "            return [g['name'] for g in genres]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "\n",
        "def get_movie_genres(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
        "    \"\"\"Get genres for internal item ID.\"\"\"\n",
        "    global GENRE_FEATURES, GENRE_NAMES\n",
        "\n",
        "    # First try: Use genre features array (most reliable)\n",
        "    if GENRE_FEATURES is not None and item_id < len(GENRE_FEATURES):\n",
        "        genre_indices = [i for i, g in enumerate(GENRE_FEATURES[item_id]) if g == 1]\n",
        "        if genre_indices and GENRE_NAMES:\n",
        "            return ', '.join([GENRE_NAMES[i] for i in genre_indices if i < len(GENRE_NAMES)])\n",
        "\n",
        "    # Second try: Get from movies_df using TMDB ID mapping\n",
        "    if movies_df is not None:\n",
        "        tmdb_id = reverse_item_map.get(item_id)\n",
        "        if tmdb_id is not None and tmdb_id in movies_df.index:\n",
        "            genres_str = movies_df.loc[tmdb_id, 'genres']\n",
        "            genres = parse_genres(genres_str)\n",
        "            if genres:\n",
        "                return ', '.join(genres)\n",
        "\n",
        "    return \"Unknown\"\n",
        "\n",
        "\n",
        "def predict_score(model, user_id: int, item_id: int,\n",
        "                genre_vector: Optional[np.ndarray] = None,\n",
        "                synopsis_embedding: Optional[np.ndarray] = None,\n",
        "                device: str = DEVICE) -> float:\n",
        "    \"\"\"Predict score for a user-item pair.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    user_tensor = torch.LongTensor([user_id]).to(device)\n",
        "    item_tensor = torch.LongTensor([item_id]).to(device)\n",
        "\n",
        "    kwargs = {}\n",
        "    if genre_vector is not None:\n",
        "        kwargs['genre_features'] = torch.FloatTensor([genre_vector]).to(device)\n",
        "    if synopsis_embedding is not None:\n",
        "        kwargs['synopsis_embeddings'] = torch.FloatTensor([synopsis_embedding]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(user_tensor, item_tensor, **kwargs)\n",
        "        score = torch.sigmoid(logits).squeeze(-1).item()\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def recommend(model, user_id: int, k: int = 10,\n",
        "             item_genre_features: Optional[np.ndarray] = None,\n",
        "             item_synopsis_embeddings: Optional[np.ndarray] = None,\n",
        "             seen_items: Optional[List[int]] = None,\n",
        "             device: str = DEVICE) -> List[Dict]:\n",
        "    \"\"\"Recommend top-K items for a user.\"\"\"\n",
        "    model.eval()\n",
        "    num_items = model.num_items\n",
        "\n",
        "    candidate_items = list(range(num_items))\n",
        "    if seen_items is not None:\n",
        "        candidate_items = [item for item in candidate_items if item not in seen_items]\n",
        "\n",
        "    user_tensor = torch.LongTensor([user_id] * len(candidate_items)).to(device)\n",
        "    item_tensor = torch.LongTensor(candidate_items).to(device)\n",
        "\n",
        "    kwargs = {}\n",
        "    if item_genre_features is not None:\n",
        "        kwargs['genre_features'] = torch.FloatTensor(item_genre_features[candidate_items]).to(device)\n",
        "    if item_synopsis_embeddings is not None:\n",
        "        kwargs['synopsis_embeddings'] = torch.FloatTensor(item_synopsis_embeddings[candidate_items]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(user_tensor, item_tensor, **kwargs)\n",
        "        scores = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
        "\n",
        "    top_indices = np.argsort(scores)[::-1][:k]\n",
        "\n",
        "    recommendations = []\n",
        "    for idx in top_indices:\n",
        "        item_id = int(candidate_items[idx])\n",
        "        recommendations.append({\n",
        "            'item_id': item_id,\n",
        "            'score': float(scores[idx]),\n",
        "            'rank': len(recommendations) + 1,\n",
        "            'title': get_movie_title(item_id, movies_df),\n",
        "            'genres': get_movie_genres(item_id, movies_df),\n",
        "        })\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "def load_multiple_models(model_paths: Dict[str, str], device: str = DEVICE) -> Dict[str, tuple]:\n",
        "    \"\"\"Load multiple models for comparison.\"\"\"\n",
        "    loaded = {}\n",
        "    for name, path in model_paths.items():\n",
        "        try:\n",
        "            model_obj, checkpoint = NeuMFPlus.load(path, device=device)\n",
        "            model_obj.eval()\n",
        "            loaded[name] = (model_obj, checkpoint)\n",
        "            print(f\"âœ… Loaded: {name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load {name}: {e}\")\n",
        "    return loaded\n",
        "\n",
        "print(\"âœ… Helper functions defined with reverse mapping support!\")"
      ],
      "metadata": {
        "id": "mL2KZF8pdpow",
        "outputId": "fbc18b3b-0efb-4759-e3b8-be3d2fea722e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Helper functions defined with reverse mapping support!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "9YUpsemic-RE",
        "outputId": "af78b553-9fea-4b46-ff0d-134a72a048b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6/6] Saving to: /content/drive/MyDrive/NCF-Movie-Recommender/data/item_genre_features.npy\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Save\n",
        "print(f\"\\n[6/6] Saving to: {genre_output_path}\")\n",
        "os.makedirs(os.path.dirname(genre_output_path), exist_ok=True)\n",
        "np.save(genre_output_path, genre_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "cNyuAvmvc-RF",
        "outputId": "c1fc06d7-da3e-4c09-e97c-667bce119d51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TOP-10 RECOMMENDATIONS FOR USER 109\n",
            "======================================================================\n",
            "\n",
            "Rank   Score      Title                                              Genres\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1      0.9348     Movie 352                                          Unknown\n",
            "2      0.9069     Movie 148                                          Unknown\n",
            "3      0.9032     Movie 2773                                         Unknown\n",
            "4      0.8915     Movie 293                                          Unknown\n",
            "5      0.8895     Movie 587                                          Unknown\n",
            "6      0.8842     Movie 2487                                         Unknown\n",
            "7      0.8765     Movie 340                                          Unknown\n",
            "8      0.8745     Movie 2874                                         Unknown\n",
            "9      0.8706     Movie 315                                          Unknown\n",
            "10     0.8679     Movie 476                                          Unknown\n"
          ]
        }
      ],
      "source": [
        "# @title Get top-K recommendations\n",
        "# @markdown Enter user ID and number of recommendations:\n",
        "\n",
        "user_id_rec = 109  # @param {type:\"integer\"}\n",
        "k_recommendations = 10  # @param {type:\"integer\", min:1, max:50}\n",
        "\n",
        "if user_id_rec >= NUM_USERS:\n",
        "    print(f\"âŒ Invalid user ID. Must be less than {NUM_USERS}.\")\n",
        "else:\n",
        "    recommendations = recommend(\n",
        "        model, user_id_rec, k=k_recommendations,\n",
        "        item_genre_features=GENRE_FEATURES,\n",
        "        item_synopsis_embeddings=SYNOPSIS_EMBEDDINGS,\n",
        "    )\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(f\"TOP-{k_recommendations} RECOMMENDATIONS FOR USER {user_id_rec}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(f\"\\n{'Rank':<6} {'Score':<10} {'Title':<50} {'Genres'}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "    for rec in recommendations:\n",
        "        title = rec['title'][:47] + '...' if len(rec['title']) > 47 else rec['title']\n",
        "        print(f\"{rec['rank']:<6} {rec['score']:.4f}     {title:<50} {rec['genres']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6rUN1rnc-RF"
      },
      "source": [
        "## 10. Example: Compare Multiple Users\n",
        "\n",
        "See how different users would rate the same movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "MI4Q-ZJ0c-RF",
        "outputId": "15c8ae93-7756-443e-bf7a-69b8d59e0e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "USER COMPARISON FOR ITEM: Movie 500\n",
            "Genres: Unknown\n",
            "======================================================================\n",
            "\n",
            "User ID      Score      Prediction\n",
            "----------------------------------------\n",
            "0            0.4600     Maybe\n",
            "50           0.4628     Maybe\n",
            "100          0.4573     Maybe\n",
            "500          0.4614     Maybe\n",
            "1000         0.4571     Maybe\n"
          ]
        }
      ],
      "source": [
        "# @title Compare predictions for multiple users\n",
        "# @markdown Enter item ID and list of user IDs to compare:\n",
        "\n",
        "item_id_compare = 500  # @param {type:\"integer\"}\n",
        "user_ids_compare = \"0, 50, 100, 500, 1000\"  # @param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "    user_list = [int(u.strip()) for u in user_ids_compare.split(',')]\n",
        "except:\n",
        "    user_list = [0, 50, 100, 500, 1000]\n",
        "\n",
        "if item_id_compare >= NUM_ITEMS:\n",
        "    print(f\"âŒ Invalid item ID. Must be less than {NUM_ITEMS}.\")\n",
        "else:\n",
        "    print(\"=\"*70)\n",
        "    print(f\"USER COMPARISON FOR ITEM: {get_movie_title(item_id_compare, movies_df)}\")\n",
        "    print(f\"Genres: {get_movie_genres(item_id_compare, movies_df)}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(f\"\\n{'User ID':<12} {'Score':<10} {'Prediction'}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    genre_vec = GENRE_FEATURES[item_id_compare] if GENRE_FEATURES is not None else None\n",
        "    synopsis_emb = SYNOPSIS_EMBEDDINGS[item_id_compare] if SYNOPSIS_EMBEDDINGS is not None else None\n",
        "\n",
        "    for user_id in user_list:\n",
        "        if user_id >= NUM_USERS:\n",
        "            print(f\"{user_id:<12} (invalid user)\")\n",
        "            continue\n",
        "\n",
        "        score = predict_score(model, user_id, item_id_compare, genre_vec, synopsis_emb)\n",
        "\n",
        "        if score > 0.8:\n",
        "            prediction = \"Will love it!\"\n",
        "        elif score > 0.6:\n",
        "            prediction = \"Will probably like it\"\n",
        "        elif score > 0.4:\n",
        "            prediction = \"Maybe\"\n",
        "        else:\n",
        "            prediction = \"Probably not interested\"\n",
        "\n",
        "        print(f\"{user_id:<12} {score:.4f}     {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPHEH1HNc-RF"
      },
      "source": [
        "## 11. Advanced: Cold-Start Prediction for New Movies\n",
        "\n",
        "Predict how users would rate a completely new movie using only its content features (genres and synopsis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "fYri_Inyc-RF",
        "outputId": "2c23ea21-8433-4564-df8e-d9effe23308b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Sentence-BERT model...\n",
            "\n",
            "======================================================================\n",
            "COLD-START PREDICTION\n",
            "======================================================================\n",
            "\n",
            "User ID: 100\n",
            "\n",
            "New Movie:\n",
            "  Genres: Action,Sci-Fi\n",
            "  Synopsis: A group of astronauts discover a mysterious artifact on Mars that changes their understanding of hum...\n",
            "\n",
            "âœ… Predicted score: 0.4905\n",
            "\n",
            "ðŸŽ¬ This movie may not be a good fit for this user.\n"
          ]
        }
      ],
      "source": [
        "# @title Cold-start prediction for a new movie\n",
        "# @markdown Enter movie details for prediction:\n",
        "\n",
        "new_user_id = 100  # @param {type:\"integer\"}\n",
        "new_movie_genres = \"Action,Sci-Fi\"  # @param {type:\"string\"}\n",
        "new_movie_synopsis = \"A group of astronauts discover a mysterious artifact on Mars that changes their understanding of humanity's place in the universe.\"  # @param {type:\"string\"}\n",
        "\n",
        "if new_user_id >= NUM_USERS:\n",
        "    print(f\"âŒ Invalid user ID. Must be less than {NUM_USERS}.\")\n",
        "else:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    # Load SBERT model for synopsis encoding\n",
        "    print(\"Loading Sentence-BERT model...\")\n",
        "    sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Encode genres\n",
        "    genre_list = [g.strip() for g in new_movie_genres.split(',')]\n",
        "    genre_vector = np.zeros(NUM_GENRES, dtype=np.float32)\n",
        "\n",
        "    if GENRE_NAMES:\n",
        "        for genre in genre_list:\n",
        "            if genre in GENRE_NAMES:\n",
        "                idx = GENRE_NAMES.index(genre)\n",
        "                genre_vector[idx] = 1.0\n",
        "\n",
        "    # Encode synopsis\n",
        "    synopsis_embedding = sbert.encode(new_movie_synopsis, show_progress_bar=False)\n",
        "    synopsis_embedding = np.array(synopsis_embedding, dtype=np.float32)\n",
        "\n",
        "    # Use a placeholder item ID (last item as reference)\n",
        "    placeholder_item_id = NUM_ITEMS - 1\n",
        "\n",
        "    # Predict\n",
        "    score = predict_score(\n",
        "        model, new_user_id, placeholder_item_id,\n",
        "        genre_vector=genre_vector,\n",
        "        synopsis_embedding=synopsis_embedding\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"COLD-START PREDICTION\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nUser ID: {new_user_id}\")\n",
        "    print(f\"\\nNew Movie:\")\n",
        "    print(f\"  Genres: {new_movie_genres}\")\n",
        "    print(f\"  Synopsis: {new_movie_synopsis[:100]}...\")\n",
        "    print(f\"\\nâœ… Predicted score: {score:.4f}\")\n",
        "\n",
        "    if score > 0.7:\n",
        "        print(\"\\nðŸŽ¬ This user would likely enjoy this movie!\")\n",
        "    elif score > 0.5:\n",
        "        print(\"\\nðŸŽ¬ This user might be interested in this movie.\")\n",
        "    else:\n",
        "        print(\"\\nðŸŽ¬ This movie may not be a good fit for this user.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPWWXgHYc-RF"
      },
      "source": [
        "## 12. Interactive Recommendation Widget\n",
        "\n",
        "Use this interactive widget to explore recommendations for different users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "XKE7Pc-Kc-RG",
        "outputId": "e486125f-3026-4b38-aebb-bb0f31320f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "USER ANALYSIS: User 24784\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3771487342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Count ratings for this user in training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/numeric.py\u001b[0m in \u001b[0;36m_frombuffer\u001b[0;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_frombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title Debug: Check user interaction history\n",
        "# @markdown Enter user ID to check their interaction history:\n",
        "\n",
        "debug_user_id = 24784  # @param {type:\"integer\"}\n",
        "\n",
        "if debug_user_id >= NUM_USERS:\n",
        "    print(f\"âŒ Invalid user ID. Must be less than {NUM_USERS}.\")\n",
        "else:\n",
        "    print(\"=\"*70)\n",
        "    print(f\"USER ANALYSIS: User {debug_user_id}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Check if this user has interaction history\n",
        "    # Load training data to check\n",
        "    import pickle\n",
        "\n",
        "    train_path = os.path.join(DATA_DIR, \"train.pkl\")\n",
        "    val_path = os.path.join(DATA_DIR, \"val.pkl\")\n",
        "\n",
        "    try:\n",
        "        with open(train_path, 'rb') as f:\n",
        "            train_data = pickle.load(f)\n",
        "\n",
        "        # Count ratings for this user in training set\n",
        "        user_train_items = train_data['user_item_matrix'][debug_user_id].nonzero()[1]\n",
        "        train_count = len(user_train_items)\n",
        "\n",
        "        print(f\"\\nTraining set:\")\n",
        "        print(f\"  Items rated: {train_count}\")\n",
        "\n",
        "        if train_count > 0:\n",
        "            print(f\"  Sample items (first 10): {user_train_items[:10].tolist()}\")\n",
        "\n",
        "            # Get some sample movie titles\n",
        "            if movies_df is not None and len(user_train_items) > 0:\n",
        "                print(f\"\\n  Sample movies rated by this user:\")\n",
        "                for item_id in user_train_items[:5]:\n",
        "                    title = get_movie_title(item_id, movies_df)\n",
        "                    genres = get_movie_genres(item_id, movies_df)\n",
        "                    print(f\"    - {title} ({genres})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error loading training data: {e}\")\n",
        "\n",
        "    # Check validation set\n",
        "    try:\n",
        "        with open(val_path, 'rb') as f:\n",
        "            val_data = pickle.load(f)\n",
        "\n",
        "        user_val_items = val_data['user_item_matrix'][debug_user_id].nonzero()[1]\n",
        "        val_count = len(user_val_items)\n",
        "\n",
        "        print(f\"\\nValidation set:\")\n",
        "        print(f\"  Items rated: {val_count}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error loading validation data: {e}\")\n",
        "\n",
        "    total_interactions = train_count + val_count if 'train_count' in locals() else 0\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TOTAL INTERACTIONS: {total_interactions}\")\n",
        "\n",
        "    if total_interactions == 0:\n",
        "        print(\"\\nâš ï¸  This user has NO interaction history!\")\n",
        "        print(\"   â†’ Model is using default/popularity-based recommendations\")\n",
        "        print(\"   â†’ Try a user with more interactions (e.g., user 100, 500, 1000)\")\n",
        "    elif total_interactions < 10:\n",
        "        print(\"\\nâš ï¸  This user has very few interactions!\")\n",
        "        print(\"   â†’ Recommendations may not be very personalized\")\n",
        "        print(\"   â†’ Consider using a user with more history\")\n",
        "    else:\n",
        "        print(f\"\\nâœ… This user has good interaction history ({total_interactions} items)\")\n",
        "        print(\"   â†’ Recommendations should be personalized\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Find users with good interaction history\n",
        "# @markdown This will find users with many ratings to test personalized recommendations.\n",
        "\n",
        "import pickle\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINDING ACTIVE USERS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load training data\n",
        "train_path = os.path.join(DATA_DIR, \"train.pkl\")\n",
        "with open(train_path, 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "# Count interactions per user\n",
        "user_interaction_counts = []\n",
        "for user_id in range(train_data['user_item_matrix'].shape[0]):\n",
        "    count = len(train_data['user_item_matrix'][user_id].nonzero()[1])\n",
        "    user_interaction_counts.append((user_id, count))\n",
        "\n",
        "# Sort by interaction count (descending)\n",
        "user_interaction_counts.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(f\"\\nTop 20 Most Active Users:\")\n",
        "print(f\"{'User ID':<12} {'Ratings':<10} {'Status'}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for user_id, count in user_interaction_counts[:20]:\n",
        "    if count > 100:\n",
        "        status = \"Very Active âœ…\"\n",
        "    elif count > 50:\n",
        "        status = \"Active â­\"\n",
        "    elif count > 20:\n",
        "        status = \"Moderate\"\n",
        "    else:\n",
        "        status = \"Low\"\n",
        "    print(f\"{user_id:<12} {count:<10} {status}\")\n",
        "\n",
        "# Statistics\n",
        "all_counts = [count for _, count in user_interaction_counts]\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STATISTICS:\")\n",
        "print(f\"  Total users: {len(all_counts):,}\")\n",
        "print(f\"  Mean ratings/user: {np.mean(all_counts):.1f}\")\n",
        "print(f\"  Median ratings/user: {np.median(all_counts):.1f}\")\n",
        "print(f\"  Max ratings/user: {np.max(all_counts)}\")\n",
        "print(f\"  Min ratings/user: {np.min(all_counts)}\")\n",
        "\n",
        "# Count by activity level\n",
        "very_active = sum(1 for c in all_counts if c > 100)\n",
        "active = sum(1 for c in all_counts if c > 50)\n",
        "moderate = sum(1 for c in all_counts if c > 20)\n",
        "\n",
        "print(f\"\\nACTIVITY LEVELS:\")\n",
        "print(f\"  Very Active (>100 ratings): {very_active:,} users ({very_active/len(all_counts)*100:.1f}%)\")\n",
        "print(f\"  Active (>50 ratings): {active:,} users ({active/len(all_counts)*100:.1f}%)\")\n",
        "print(f\"  Moderate (>20 ratings): {moderate:,} users ({moderate/len(all_counts)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nðŸ’¡ SUGGESTION: Try user IDs from the 'Very Active' list above for personalized recommendations!\")\n",
        "print(f\"   Example: User {user_interaction_counts[0][0]} has {user_interaction_counts[0][1]} ratings\")"
      ],
      "metadata": {
        "id": "N-RFA0lVeHpl",
        "outputId": "27d6d90f-f371-4168-8c06-9626f240fba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FINDING ACTIVE USERS\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3839492095.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Count interactions per user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/numeric.py\u001b[0m in \u001b[0;36m_frombuffer\u001b[0;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_frombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b6ca5cdc5af4840a14b88c1027c7aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "NeuMFPlus_best.pt  (NeuMFPlus_best.pt)",
              "NeuMFPlus_best_best.pt  (NeuMFPlus_best_best.pt)",
              "NeuMFPlus_genre_best.pt  (NeuMF+ (Genre))",
              "NeuMFPlus_genre_synopsis_bestt.pt  (NeuMF+ (Genre + Synopsis))",
              "NeuMF_best.pt  (NeuMF (Baseline))"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Select model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_d8aeaaabd31b4ac98942974ce084aca5",
            "style": "IPY_MODEL_088e656a02184ea98a614b8781e06c17"
          }
        },
        "d8aeaaabd31b4ac98942974ce084aca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088e656a02184ea98a614b8781e06c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "ad0dfedaed944b9d964de90a4d9a08dc": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_471883c16b8a47ea904c54bb23dcb42f",
            "msg_id": "",
            "outputs": []
          }
        },
        "471883c16b8a47ea904c54bb23dcb42f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7639eed51b44bfc9af0c62a4429636a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Load Model",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_90d6164ae7fc4ec7a23d4e732eb8ea00",
            "style": "IPY_MODEL_0885896f1b964db297043f3d80226284",
            "tooltip": ""
          }
        },
        "90d6164ae7fc4ec7a23d4e732eb8ea00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0885896f1b964db297043f3d80226284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "95f2b8d0f25c43f8bdc9a068d61f2e63": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_656896b9d519485ea2d40de8327ff9d4",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Loading model from: NeuMFPlus_best_best.pt\n",
                  "Path: /content/drive/MyDrive/NCF-Movie-Recommender/experiments/trained_models/NeuMFPlus_best_best.pt\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\n",
                  "======================================================================\n",
                  "MODEL CONFIGURATION\n",
                  "======================================================================\n",
                  "use_genre: True\n",
                  "use_synopsis: True\n",
                  "use_gated_fusion: True\n",
                  "\n",
                  "Parameters: 18,323,338\n",
                  "\n",
                  "Validation Metrics:\n",
                  "  hr@10: 0.9711\n",
                  "  ndcg@10: 0.7313\n",
                  "  auc: 0.9169\n",
                  "\n",
                  "----------------------------------------------------------------------\n",
                  "REQUIRED FEATURES FOR INFERENCE:\n",
                  "  âœ… Genre features (item_genre_features.npy)\n",
                  "  âœ… Synopsis embeddings (item_synopsis_embeddings.npy)\n",
                  "----------------------------------------------------------------------\n",
                  "\n",
                  "âœ… Model loaded successfully!\n"
                ]
              }
            ]
          }
        },
        "656896b9d519485ea2d40de8327ff9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}