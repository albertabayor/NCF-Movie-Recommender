{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Synopsis Embeddings for NeuMF+\n",
    "\n",
    "This notebook extracts **synopsis embeddings** using Sentence-BERT.\n",
    "\n",
    "**What it does:**\n",
    "1. Loads movie overviews from `movies_metadata.csv`\n",
    "2. Converts text to 384-dimensional vectors using Sentence-BERT\n",
    "3. Saves embeddings for use in NeuMF+ training\n",
    "\n",
    "**Why this matters:**\n",
    "- NeuMF+ with genre only: HR@10 ~0.08-0.15\n",
    "- NeuMF+ with genre + synopsis: HR@10 ~0.12-0.20 (better!)\n",
    "\n",
    "**Prerequisites:**\n",
    "- Google Drive with: `movies_metadata.csv`, `links.csv`\n",
    "- Colab Pro (T4 GPU recommended)\n",
    "- Estimated time: 30-60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✓ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/albertabayor/NCF-Movie-Recommender.git\n",
    "\n",
    "import os\n",
    "os.chdir('NCF-Movie-Recommender')\n",
    "!git pull origin main\n",
    "\n",
    "# Link datasets from Drive\n",
    "!rm -rf datasets\n",
    "!ln -s \"/content/drive/MyDrive/NCF-Movie-Recommender/datasets\" datasets\n",
    "\n",
    "# Link data folder\n",
    "!mkdir -p /content/drive/MyDrive/NCF-Movie-Recommender/data\n",
    "!rm -rf data\n",
    "!ln -s /content/drive/MyDrive/NCF-Movie-Recommender/data data\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q sentence-transformers tqdm\n",
    "\n",
    "print(\"\\n✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check required files\n",
    "required_files = ['movies_metadata.csv', 'links.csv']\n",
    "datasets_path = 'datasets'\n",
    "\n",
    "print(\"Checking dataset files...\\n\")\n",
    "all_exist = True\n",
    "for filename in required_files:\n",
    "    filepath = os.path.join(datasets_path, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / 1024 / 1024\n",
    "        print(f\"✓ {filename}: {size:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"❌ {filename}: NOT FOUND\")\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n✓ All required files found!\")\n",
    "else:\n",
    "    print(\"\\n❌ Some files are missing. Please upload them to Google Drive first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Synopsis Embeddings\n",
    "\n",
    "This will:\n",
    "1. Load Sentence-BERT model (all-MiniLM-L6-v2)\n",
    "2. Extract embeddings for ~45K movie overviews\n",
    "3. Save to Google Drive for later use\n",
    "\n",
    "**Estimated time:** 30-60 minutes on T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING SYNOPSIS EMBEDDINGS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis will take 30-60 minutes on T4 GPU\")\n",
    "print(\"\\nPlease be patient, the notebook will continue running...\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Run extraction\n",
    "exec(open('extract_synopsis_embeddings.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Extracted Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load embeddings\n",
    "embeddings = np.load('data/synopsis_embeddings.npy')\n",
    "\n",
    "# Load metadata\n",
    "with open('data/synopsis_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION - SYNOPSIS EMBEDDINGS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nShape: {embeddings.shape}\")\n",
    "print(f\"  Movies: {metadata['num_movies']:,}\")\n",
    "print(f\"  Embedding dim: {metadata['embedding_dim']}\")\n",
    "print(f\"  Memory: {embeddings.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample embeddings (first 3 movies):\")\n",
    "for i in range(min(3, len(embeddings))):\n",
    "    emb = embeddings[i]\n",
    "    print(f\"  Movie {i}: shape={emb.shape}, mean={emb.mean():.4f}, std={emb.std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Embeddings look good!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What happened:**\n",
    "1. ✅ Loaded Sentence-BERT model\n",
    "2. ✅ Extracted embeddings for ~45K movie overviews\n",
    "3. ✅ Saved embeddings to Google Drive\n",
    "\n",
    "**Files created:**\n",
    "- `data/synopsis_embeddings.npy` (45K × 384 float vectors)\n",
    "- `data/synopsis_metadata.pkl` (metadata and mappings)\n",
    "- `data/tmdb_to_movieid.pkl` (TMDB ID → MovieLens ID mapping)\n",
    "\n",
    "**Next steps:**\n",
    "1. Update preprocessing to link synopsis embeddings to movieIds\n",
    "2. Train NeuMF+ with `use_synopsis=True`\n",
    "3. Enjoy improved recommendations with genre + synopsis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
