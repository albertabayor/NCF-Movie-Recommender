{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCF Movie Recommender - Model Inference on Colab\n",
    "\n",
    "This notebook demonstrates how to use trained NCF/NeuMF+ models for movie recommendations.\n",
    "\n",
    "**Features:**\n",
    "- Load trained models from Google Drive\n",
    "- Generate top-K movie recommendations for users\n",
    "- Predict scores for user-item pairs\n",
    "- Handle cold-start scenarios (new movies)\n",
    "- Display movie titles and genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup - Mount Google Drive\n",
    "\n",
    "This notebook expects your trained models and data to be in Google Drive.\n",
    "\n",
    "**Required structure in Google Drive:**\n",
    "```\n",
    "MyDrive/\n",
    "â””â”€â”€ NCF-Movie-Recommender/\n",
    "    â”œâ”€â”€ data/                    # Processed data files\n",
    "    â”‚   â”œâ”€â”€ mappings.pkl         # User/item mappings\n",
    "    â”‚   â”œâ”€â”€ item_synopsis_embeddings.npy\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ datasets/                # Raw datasets\n",
    "    â”‚   â””â”€â”€ movies_metadata.csv  # Movie titles and info\n",
    "    â””â”€â”€ experiments/\n",
    "        â””â”€â”€ trained_models/      # Trained model checkpoints\n",
    "            â”œâ”€â”€ NeuMFPlus_genre_synopsis_best.pt\n",
    "            â””â”€â”€ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Paths\n",
    "\n",
    "Update these paths to match your Google Drive structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configure paths\n",
    "import os\n",
    "\n",
    "# @markdown **Base path for NCF-Movie-Recommender project:**\n",
    "GDRIVE_BASE = \"/content/drive/MyDrive/NCF-Movie-Recommender\"  # @param {type:\"string\"}\n",
    "\n",
    "# Paths relative to your Google Drive base\n",
    "DATA_DIR = os.path.join(GDRIVE_BASE, \"data\")\n",
    "DATASETS_DIR = os.path.join(GDRIVE_BASE, \"datasets\")\n",
    "MODELS_DIR = os.path.join(GDRIVE_BASE, \"experiments\", \"trained_models\")\n",
    "\n",
    "print(f\"ðŸ“ Base directory: {GDRIVE_BASE}\")\n",
    "print(f\"ðŸ“ Data directory: {DATA_DIR}\")\n",
    "print(f\"ðŸ“ Datasets directory: {DATASETS_DIR}\")\n",
    "print(f\"ðŸ“ Models directory: {MODELS_DIR}\")\n",
    "\n",
    "# Verify directories exist\n",
    "if os.path.exists(DATA_DIR):\n",
    "    data_files = os.listdir(DATA_DIR)\n",
    "    print(f\"\\nâœ… Data directory found! Files: {len(data_files)}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Data directory not found: {DATA_DIR}\")\n",
    "\n",
    "if os.path.exists(DATASETS_DIR):\n",
    "    datasets_files = os.listdir(DATASETS_DIR)\n",
    "    print(f\"âœ… Datasets directory found! Files: {len(datasets_files)}\")\n",
    "else:\n",
    "    print(f\"âŒ Datasets directory not found: {DATASETS_DIR}\")\n",
    "\n",
    "if os.path.exists(MODELS_DIR):\n",
    "    model_files = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n",
    "    print(f\"âœ… Models directory found! Checkpoints: {len(model_files)}\")\n",
    "    if model_files:\n",
    "        print(\"\\nAvailable models:\")\n",
    "        for f in sorted(model_files):\n",
    "            print(f\"  â€¢ {f}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Models directory not found: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Install required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install -q torch numpy pandas sentence-transformers tqdm\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "print(\"âœ… Dependencies installed!\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"   Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Model Architecture\n",
    "\n",
    "This section defines the NeuMF+ model architecture to match your trained checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define NeuMF+ Model (matching trained checkpoints)\n",
    "import torch.nn as nn\n",
    "\n",
    "class ContentEncoder(nn.Module):\n",
    "    \"\"\"Encode content features (genre + synopsis) into embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_genres: int, genre_embed_dim: int = 64,\n",
    "                 synopsis_embed_dim: int = 384, content_embed_dim: int = 256,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.genre_encoder = nn.Sequential(\n",
    "            nn.Linear(num_genres, genre_embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "        self.synopsis_projection = nn.Sequential(\n",
    "            nn.Linear(synopsis_embed_dim, synopsis_embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "        combined_dim = genre_embed_dim + synopsis_embed_dim // 2\n",
    "        self.content_encoder = nn.Sequential(\n",
    "            nn.Linear(combined_dim, content_embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, genre_features, synopsis_embeddings):\n",
    "        genre_embed = self.genre_encoder(genre_features)\n",
    "        synopsis_embed = self.synopsis_projection(synopsis_embeddings)\n",
    "        combined = torch.cat([genre_embed, synopsis_embed], dim=-1)\n",
    "        return self.content_encoder(combined)\n",
    "\n",
    "\n",
    "class GatedFusion(nn.Module):\n",
    "    \"\"\"Gated fusion for CF and content embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, cf_dim: int, content_dim: int, hidden_dim: int = 64, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gate_network = nn.Sequential(\n",
    "            nn.Linear(cf_dim + content_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, cf_embed, content_embed):\n",
    "        combined = torch.cat([cf_embed, content_embed], dim=-1)\n",
    "        gate = self.gate_network(combined)\n",
    "        \n",
    "        if cf_embed.shape[-1] != content_embed.shape[-1]:\n",
    "            if cf_embed.shape[-1] > content_embed.shape[-1]:\n",
    "                target_dim = cf_embed.shape[-1]\n",
    "                if not hasattr(self, '_content_proj'):\n",
    "                    self._content_proj = nn.Linear(content_embed.shape[-1], target_dim).to(cf_embed.device)\n",
    "                content_embed = self._content_proj(content_embed)\n",
    "            else:\n",
    "                target_dim = content_embed.shape[-1]\n",
    "                if not hasattr(self, '_cf_proj'):\n",
    "                    self._cf_proj = nn.Linear(cf_embed.shape[-1], target_dim).to(cf_embed.device)\n",
    "                cf_embed = self._cf_proj(cf_embed)\n",
    "        \n",
    "        fused = gate * cf_embed + (1 - gate) * content_embed\n",
    "        return fused, gate\n",
    "\n",
    "\n",
    "class NeuMFPlus(nn.Module):\n",
    "    \"\"\"NeuMF+ with Genre, Synopsis, and Gated Fusion.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        num_genres: int,\n",
    "        # CF (NeuMF) parameters\n",
    "        embedding_dim: int = 32,\n",
    "        gmf_hidden_dim: int = 8,\n",
    "        mlp_hidden_dims: list = None,\n",
    "        mlp_dropout: float = 0.2,\n",
    "        fusion_dim: int = 32,\n",
    "        # Content encoder parameters\n",
    "        genre_embed_dim: int = 64,\n",
    "        synopsis_embed_dim: int = 384,\n",
    "        content_embed_dim: int = 256,\n",
    "        content_encoder_dropout: float = 0.1,\n",
    "        # Gated fusion parameters\n",
    "        gated_fusion_hidden_dim: int = 64,\n",
    "        gated_fusion_dropout: float = 0.1,\n",
    "        # Output parameters\n",
    "        output_hidden_dim: int = 64,\n",
    "        output_dropout: float = 0.2,\n",
    "        # Ablation study flags\n",
    "        use_genre: bool = True,\n",
    "        use_synopsis: bool = True,\n",
    "        use_gated_fusion: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_genres = num_genres\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.use_genre = use_genre\n",
    "        self.use_synopsis = use_synopsis\n",
    "        self.use_gated_fusion = use_gated_fusion\n",
    "        self.synopsis_embed_dim = synopsis_embed_dim\n",
    "        self.content_embed_dim = content_embed_dim\n",
    "\n",
    "        # Calculate content dimensions\n",
    "        if use_genre and use_synopsis:\n",
    "            self.content_encoder = ContentEncoder(\n",
    "                num_genres=num_genres,\n",
    "                genre_embed_dim=genre_embed_dim,\n",
    "                synopsis_embed_dim=synopsis_embed_dim,\n",
    "                content_embed_dim=content_embed_dim,\n",
    "                dropout=content_encoder_dropout,\n",
    "            )\n",
    "            actual_content_dim = content_embed_dim\n",
    "        elif use_genre:\n",
    "            self.genre_encoder = nn.Sequential(\n",
    "                nn.Linear(num_genres, genre_embed_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(content_encoder_dropout),\n",
    "            )\n",
    "            actual_content_dim = genre_embed_dim\n",
    "        elif use_synopsis:\n",
    "            self.synopsis_projection = nn.Sequential(\n",
    "                nn.Linear(synopsis_embed_dim, synopsis_embed_dim // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(content_encoder_dropout),\n",
    "            )\n",
    "            actual_content_dim = synopsis_embed_dim // 2\n",
    "        else:\n",
    "            actual_content_dim = 0\n",
    "\n",
    "        # CF (NeuMF) branch - separate embeddings for GMF and MLP\n",
    "        self.gmf_user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.gmf_item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.mlp_user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.mlp_item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Initialize embeddings\n",
    "        nn.init.xavier_uniform_(self.gmf_user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.gmf_item_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.mlp_user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.mlp_item_embedding.weight)\n",
    "\n",
    "        # GMF branch\n",
    "        self.gmf_fc = nn.Linear(embedding_dim, gmf_hidden_dim)\n",
    "\n",
    "        # MLP branch\n",
    "        mlp_hidden_dims = mlp_hidden_dims or [128, 64, 32]\n",
    "        mlp_input_dim = 2 * embedding_dim\n",
    "        self.mlp_layers = nn.ModuleList()\n",
    "        self.mlp_dropout_layers = nn.ModuleList()\n",
    "\n",
    "        prev_dim = mlp_input_dim\n",
    "        for hidden_dim in mlp_hidden_dims:\n",
    "            self.mlp_layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            self.mlp_dropout_layers.append(nn.Dropout(mlp_dropout))\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        # NeuMF fusion layer\n",
    "        self.neumf_fusion_fc = nn.Linear(gmf_hidden_dim + prev_dim, fusion_dim)\n",
    "        self.neumf_fusion_dropout = nn.Dropout(0.1)\n",
    "        self.cf_output_dim = fusion_dim\n",
    "\n",
    "        # Content fusion\n",
    "        if actual_content_dim > 0:\n",
    "            if use_gated_fusion:\n",
    "                self.gated_fusion = GatedFusion(\n",
    "                    cf_dim=self.cf_output_dim,\n",
    "                    content_dim=actual_content_dim,\n",
    "                    hidden_dim=gated_fusion_hidden_dim,\n",
    "                    dropout=gated_fusion_dropout,\n",
    "                )\n",
    "                self.final_input_dim = max(self.cf_output_dim, actual_content_dim)\n",
    "            else:\n",
    "                self.final_input_dim = self.cf_output_dim + actual_content_dim\n",
    "        else:\n",
    "            self.final_input_dim = self.cf_output_dim\n",
    "\n",
    "        # Output layers\n",
    "        self.output_fc = nn.Sequential(\n",
    "            nn.Linear(self.final_input_dim, output_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(output_dropout),\n",
    "            nn.Linear(output_hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        \"\"\"Initialize weights.\"\"\"\n",
    "        if self.use_genre and not self.use_synopsis:\n",
    "            if hasattr(self, 'genre_encoder'):\n",
    "                for module in self.genre_encoder:\n",
    "                    if isinstance(module, nn.Linear):\n",
    "                        nn.init.xavier_uniform_(module.weight)\n",
    "                        if module.bias is not None:\n",
    "                            nn.init.zeros_(module.bias)\n",
    "\n",
    "        if self.use_synopsis and not self.use_genre:\n",
    "            if hasattr(self, 'synopsis_projection'):\n",
    "                for module in self.synopsis_projection:\n",
    "                    if isinstance(module, nn.Linear):\n",
    "                        nn.init.xavier_uniform_(module.weight)\n",
    "                        if module.bias is not None:\n",
    "                            nn.init.zeros_(module.bias)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.gmf_fc.weight)\n",
    "        nn.init.zeros_(self.gmf_fc.bias)\n",
    "\n",
    "        for layer in self.mlp_layers:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.neumf_fusion_fc.weight)\n",
    "        nn.init.zeros_(self.neumf_fusion_fc.bias)\n",
    "\n",
    "        for module in self.output_fc:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        user_ids: torch.Tensor,\n",
    "        item_ids: torch.Tensor,\n",
    "        genre_features: torch.Tensor = None,\n",
    "        synopsis_embeddings: torch.Tensor = None,\n",
    "        return_gate: bool = False,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of NeuMF+.\"\"\"\n",
    "        # GMF\n",
    "        gmf_user_embed = self.gmf_user_embedding(user_ids)\n",
    "        gmf_item_embed = self.gmf_item_embedding(item_ids)\n",
    "        gmf_output = gmf_user_embed * gmf_item_embed\n",
    "        gmf_hidden = self.gmf_fc(gmf_output)\n",
    "\n",
    "        # MLP\n",
    "        mlp_user_embed = self.mlp_user_embedding(user_ids)\n",
    "        mlp_item_embed = self.mlp_item_embedding(item_ids)\n",
    "        mlp_concat = torch.cat([mlp_user_embed, mlp_item_embed], dim=-1)\n",
    "\n",
    "        x = mlp_concat\n",
    "        for layer, dropout in zip(self.mlp_layers, self.mlp_dropout_layers):\n",
    "            x = layer(x)\n",
    "            x = torch.relu(x)\n",
    "            x = dropout(x)\n",
    "\n",
    "        mlp_hidden = x\n",
    "\n",
    "        # NeuMF fusion\n",
    "        neumf_input = torch.cat([gmf_hidden, mlp_hidden], dim=-1)\n",
    "        cf_embed = self.neumf_fusion_fc(neumf_input)\n",
    "        cf_embed = torch.relu(cf_embed)\n",
    "        cf_embed = self.neumf_fusion_dropout(cf_embed)\n",
    "\n",
    "        # Content Branch\n",
    "        content_embed = None\n",
    "        if self.use_genre and self.use_synopsis:\n",
    "            if genre_features is None or synopsis_embeddings is None:\n",
    "                batch_size = user_ids.size(0)\n",
    "                device = user_ids.device\n",
    "                if genre_features is None:\n",
    "                    genre_features = torch.zeros(batch_size, self.num_genres, device=device)\n",
    "                if synopsis_embeddings is None:\n",
    "                    synopsis_embeddings = torch.zeros(batch_size, self.synopsis_embed_dim, device=device)\n",
    "            content_embed = self.content_encoder(genre_features, synopsis_embeddings)\n",
    "        elif self.use_genre:\n",
    "            if genre_features is None:\n",
    "                batch_size = user_ids.size(0)\n",
    "                device = user_ids.device\n",
    "                genre_features = torch.zeros(batch_size, self.num_genres, device=device)\n",
    "            content_embed = self.genre_encoder(genre_features)\n",
    "        elif self.use_synopsis:\n",
    "            if synopsis_embeddings is None:\n",
    "                batch_size = user_ids.size(0)\n",
    "                device = user_ids.device\n",
    "                synopsis_embeddings = torch.zeros(batch_size, self.synopsis_embed_dim, device=device)\n",
    "            content_embed = self.synopsis_projection(synopsis_embeddings)\n",
    "\n",
    "        # Fusion\n",
    "        if content_embed is not None:\n",
    "            if self.use_gated_fusion:\n",
    "                final_embed, gate = self.gated_fusion(cf_embed, content_embed)\n",
    "            else:\n",
    "                final_embed = torch.cat([cf_embed, content_embed], dim=-1)\n",
    "                gate = None\n",
    "        else:\n",
    "            final_embed = cf_embed\n",
    "            gate = None\n",
    "\n",
    "        # Output\n",
    "        output = self.output_fc(final_embed)\n",
    "\n",
    "        if return_gate:\n",
    "            return output, gate\n",
    "        return output\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, checkpoint_path: str, device: str = 'cuda'):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        config = checkpoint['model_config']\n",
    "\n",
    "        model = cls(\n",
    "            num_users=config['num_users'],\n",
    "            num_items=config['num_items'],\n",
    "            num_genres=config['num_genres'],\n",
    "            use_genre=config['use_genre'],\n",
    "            use_synopsis=config['use_synopsis'],\n",
    "            use_gated_fusion=config['use_gated_fusion'],\n",
    "        )\n",
    "\n",
    "        # Load state_dict with strict=False to handle version mismatches\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "        model = model.to(device)\n",
    "\n",
    "        return model, checkpoint\n",
    "\n",
    "print(\"âœ… Model architecture defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data and Mappings\n",
    "\n",
    "Load the processed data files including mappings, genre features, and movie metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load mappings and features\n",
    "\n",
    "# Load mappings\n",
    "mappings_path = os.path.join(DATA_DIR, \"mappings.pkl\")\n",
    "with open(mappings_path, 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "NUM_USERS = mappings['num_users']\n",
    "NUM_ITEMS = mappings['num_items']\n",
    "NUM_GENRES = mappings['num_genres']\n",
    "GENRE_NAMES = mappings.get('genre_names', [])\n",
    "\n",
    "print(f\"âœ… Mappings loaded!\")\n",
    "print(f\"   Users: {NUM_USERS:,}\")\n",
    "print(f\"   Items: {NUM_ITEMS:,}\")\n",
    "print(f\"   Genres: {NUM_GENRES}\")\n",
    "if GENRE_NAMES:\n",
    "    print(f\"   Genre names: {GENRE_NAMES}\")\n",
    "\n",
    "# Load genre features (if available)\n",
    "# Note: This file may not exist - genre features can be generated from movies_metadata.csv\n",
    "genre_path = os.path.join(DATA_DIR, \"item_genre_features.npy\")\n",
    "if os.path.exists(genre_path):\n",
    "    GENRE_FEATURES = np.load(genre_path)\n",
    "    print(f\"\\nâœ… Genre features loaded: {GENRE_FEATURES.shape}\")\n",
    "else:\n",
    "    GENRE_FEATURES = None\n",
    "    print(f\"\\nâš ï¸  Genre features not found: {genre_path}\")\n",
    "    print(f\"   Models that require genre features will use zero vectors.\")\n",
    "\n",
    "# Load synopsis embeddings\n",
    "# Note: File uses plural \"embeddings\"\n",
    "synopsis_path = os.path.join(DATA_DIR, \"item_synopsis_embeddings.npy\")\n",
    "if os.path.exists(synopsis_path):\n",
    "    SYNOPSIS_EMBEDDINGS = np.load(synopsis_path)\n",
    "    print(f\"âœ… Synopsis embeddings loaded: {SYNOPSIS_EMBEDDINGS.shape}\")\n",
    "else:\n",
    "    SYNOPSIS_EMBEDDINGS = None\n",
    "    print(f\"âš ï¸  Synopsis embeddings not found: {synopsis_path}\")\n",
    "\n",
    "# Load movie metadata for display (from datasets directory)\n",
    "metadata_path = os.path.join(DATASETS_DIR, \"movies_metadata.csv\")\n",
    "if os.path.exists(metadata_path):\n",
    "    movies_df = pd.read_csv(metadata_path, low_memory=False)\n",
    "    # Filter for valid IDs\n",
    "    movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
    "    movies_df = movies_df[movies_df['id'].notna()]\n",
    "    movies_df['id'] = movies_df['id'].astype(int)\n",
    "    movies_df = movies_df.set_index('id')\n",
    "    print(f\"\\nâœ… Movie metadata loaded: {len(movies_df):,} movies\")\n",
    "else:\n",
    "    movies_df = None\n",
    "    print(f\"\\nâš ï¸  Movie metadata not found: {metadata_path}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA LOADING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Genre features available: {'âœ… Yes' if GENRE_FEATURES is not None else 'âŒ No'}\")\n",
    "print(f\"Synopsis embeddings available: {'âœ… Yes' if SYNOPSIS_EMBEDDINGS is not None else 'âŒ No'}\")\n",
    "print(f\"Movie metadata available: {'âœ… Yes' if movies_df is not None else 'âŒ No'}\")\n",
    "\n",
    "if GENRE_FEATURES is None:\n",
    "    print(\"\\nâš ï¸  NOTE: Genre features file (item_genre_features.npy) not found.\")\n",
    "    print(\"   If you're using a model that requires genre features,\")\n",
    "    print(\"   the model will automatically use zero vectors for missing features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Trained Model\n",
    "\n",
    "Select and load one of your trained models.\n",
    "\n",
    "**Available Models:**\n",
    "| Model | Description | Features |\n",
    "|-------|-------------|----------|\n",
    "| `NeuMF_best.pt` | Baseline | Collaborative Filtering only |\n",
    "| `NeuMFPlus_genre_best.pt` | Genre-enhanced | CF + Genre features |\n",
    "| `NeuMFPlus_genre_synopsis_bestt.pt` | Full model | CF + Genre + Synopsis |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load trained model\n",
    "# @markdown Select the model checkpoint to load:\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Get available models\n",
    "available_models = [f for f in os.listdir(MODELS_DIR) if f.endswith('.pt')]\n",
    "\n",
    "# Model descriptions\n",
    "MODEL_INFO = {\n",
    "    'NeuMF_best.pt': {\n",
    "        'name': 'NeuMF (Baseline)',\n",
    "        'description': 'Collaborative Filtering only - no content features',\n",
    "        'features': 'User-Item interactions only'\n",
    "    },\n",
    "    'NeuMFPlus_genre_best.pt': {\n",
    "        'name': 'NeuMF+ (Genre)',\n",
    "        'description': 'CF + Genre features',\n",
    "        'features': 'User-Item + Movie genres'\n",
    "    },\n",
    "    'NeuMFPlus_genre_synopsis_bestt.pt': {\n",
    "        'name': 'NeuMF+ (Genre + Synopsis)',\n",
    "        'description': 'CF + Genre + Synopsis features (Full Model)',\n",
    "        'features': 'User-Item + Genres + Movie synopsis'\n",
    "    }\n",
    "}\n",
    "\n",
    "if not available_models:\n",
    "    print(f\"âŒ No models found in {MODELS_DIR}\")\n",
    "else:\n",
    "    # Create dropdown with model descriptions\n",
    "    model_options = [(f\"{m}  ({MODEL_INFO.get(m, {}).get('name', m)})\", m) for m in sorted(available_models)]\n",
    "    \n",
    "    model_dropdown = widgets.Dropdown(\n",
    "        options=model_options,\n",
    "        description='Select model:',\n",
    "        style={'description_width': 'initial'},\n",
    "    )\n",
    "    display(model_dropdown)\n",
    "    \n",
    "    # Model info display\n",
    "    info_out = widgets.Output()\n",
    "    display(info_out)\n",
    "    \n",
    "    def show_model_info(change):\n",
    "        with info_out:\n",
    "            info_out.clear_output()\n",
    "            model_name = change['new']\n",
    "            info = MODEL_INFO.get(model_name, {})\n",
    "            if info:\n",
    "                print(f\"ðŸ“‹ {info.get('name', model_name)}\")\n",
    "                print(f\"   {info.get('description', '')}\")\n",
    "                print(f\"   Features: {info.get('features', 'N/A')}\")\n",
    "    \n",
    "    model_dropdown.observe(show_model_info, names='value')\n",
    "    # Show initial info\n",
    "    show_model_info({'new': model_dropdown.value})\n",
    "    \n",
    "    # Load button\n",
    "    load_btn = widgets.Button(description='Load Model', button_style='primary')\n",
    "    display(load_btn)\n",
    "    \n",
    "    # Output area\n",
    "    out = widgets.Output()\n",
    "    display(out)\n",
    "    \n",
    "    def load_model(b):\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            model_name = model_dropdown.value\n",
    "            checkpoint_path = os.path.join(MODELS_DIR, model_name)\n",
    "            \n",
    "            print(f\"Loading model from: {model_name}\")\n",
    "            print(f\"Path: {checkpoint_path}\")\n",
    "            \n",
    "            global model, checkpoint, model_config\n",
    "            model, checkpoint = NeuMFPlus.load(checkpoint_path, device=DEVICE)\n",
    "            model.eval()\n",
    "            model_config = checkpoint['model_config']\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"MODEL CONFIGURATION\")\n",
    "            print(\"=\"*70)\n",
    "            print(f\"use_genre: {model_config.get('use_genre')}\")\n",
    "            print(f\"use_synopsis: {model_config.get('use_synopsis')}\")\n",
    "            print(f\"use_gated_fusion: {model_config.get('use_gated_fusion')}\")\n",
    "            print(f\"\\nParameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "            \n",
    "            if 'metrics' in checkpoint:\n",
    "                print(\"\\nValidation Metrics:\")\n",
    "                for k, v in checkpoint['metrics'].items():\n",
    "                    if isinstance(v, (int, float)):\n",
    "                        print(f\"  {k}: {v:.4f}\")\n",
    "            \n",
    "            # Show what features are needed\n",
    "            print(\"\\n\" + \"-\"*70)\n",
    "            print(\"REQUIRED FEATURES FOR INFERENCE:\")\n",
    "            if model_config.get('use_genre'):\n",
    "                print(\"  âœ… Genre features (item_genre_features.npy)\")\n",
    "            else:\n",
    "                print(\"  âŒ Genre features NOT needed\")\n",
    "            if model_config.get('use_synopsis'):\n",
    "                print(\"  âœ… Synopsis embeddings (item_synopsis_embeddings.npy)\")\n",
    "            else:\n",
    "                print(\"  âŒ Synopsis embeddings NOT needed\")\n",
    "            print(\"-\"*70)\n",
    "            \n",
    "            print(\"\\nâœ… Model loaded successfully!\")\n",
    "    \n",
    "    load_btn.on_click(load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Helper Functions\n",
    "\n",
    "Define helper functions for prediction and recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define helper functions\n",
    "\n",
    "def get_movie_title(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
    "    \"\"\"Get movie title for item ID.\"\"\"\n",
    "    if movies_df is None:\n",
    "        return f\"Movie {item_id}\"\n",
    "    \n",
    "    # Try to get title from movies_df\n",
    "    if item_id in movies_df.index:\n",
    "        title = movies_df.loc[item_id, 'title']\n",
    "        return title if pd.notna(title) else f\"Movie {item_id}\"\n",
    "    \n",
    "    return f\"Movie {item_id}\"\n",
    "\n",
    "\n",
    "def parse_genres(genres_str: str) -> list:\n",
    "    \"\"\"Parse genres from JSON string.\"\"\"\n",
    "    import json\n",
    "    import ast\n",
    "    \n",
    "    if pd.isna(genres_str) or genres_str == \"\":\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        genres = json.loads(genres_str)\n",
    "        return [g['name'] for g in genres]\n",
    "    except:\n",
    "        try:\n",
    "            genres = ast.literal_eval(genres_str)\n",
    "            return [g['name'] for g in genres]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "\n",
    "def get_movie_genres(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
    "    \"\"\"Get genres for item ID.\"\"\"\n",
    "    if movies_df is None or GENRE_FEATURES is None:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    if item_id in movies_df.index:\n",
    "        genres_str = movies_df.loc[item_id, 'genres']\n",
    "        genres = parse_genres(genres_str)\n",
    "        return ', '.join(genres) if genres else \"Unknown\"\n",
    "    \n",
    "    # Use genre features if available\n",
    "    if item_id < len(GENRE_FEATURES):\n",
    "        genre_indices = [i for i, g in enumerate(GENRE_FEATURES[item_id]) if g == 1]\n",
    "        if genre_indices and GENRE_NAMES:\n",
    "            return ', '.join([GENRE_NAMES[i] for i in genre_indices if i < len(GENRE_NAMES)])\n",
    "    \n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def predict_score(model, user_id: int, item_id: int, \n",
    "                genre_vector: Optional[np.ndarray] = None,\n",
    "                synopsis_embedding: Optional[np.ndarray] = None,\n",
    "                device: str = DEVICE) -> float:\n",
    "    \"\"\"Predict score for a user-item pair.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    user_tensor = torch.LongTensor([user_id]).to(device)\n",
    "    item_tensor = torch.LongTensor([item_id]).to(device)\n",
    "    \n",
    "    kwargs = {}\n",
    "    if genre_vector is not None:\n",
    "        kwargs['genre_features'] = torch.FloatTensor([genre_vector]).to(device)\n",
    "    if synopsis_embedding is not None:\n",
    "        kwargs['synopsis_embeddings'] = torch.FloatTensor([synopsis_embedding]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(user_tensor, item_tensor, **kwargs)\n",
    "        score = torch.sigmoid(logits).squeeze(-1).item()\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def recommend(model, user_id: int, k: int = 10,\n",
    "             item_genre_features: Optional[np.ndarray] = None,\n",
    "             item_synopsis_embeddings: Optional[np.ndarray] = None,\n",
    "             seen_items: Optional[List[int]] = None,\n",
    "             device: str = DEVICE) -> List[Dict]:\n",
    "    \"\"\"Recommend top-K items for a user.\"\"\"\n",
    "    model.eval()\n",
    "    num_items = model.num_items\n",
    "    \n",
    "    candidate_items = list(range(num_items))\n",
    "    if seen_items is not None:\n",
    "        candidate_items = [item for item in candidate_items if item not in seen_items]\n",
    "    \n",
    "    user_tensor = torch.LongTensor([user_id] * len(candidate_items)).to(device)\n",
    "    item_tensor = torch.LongTensor(candidate_items).to(device)\n",
    "    \n",
    "    kwargs = {}\n",
    "    if item_genre_features is not None:\n",
    "        kwargs['genre_features'] = torch.FloatTensor(item_genre_features[candidate_items]).to(device)\n",
    "    if item_synopsis_embeddings is not None:\n",
    "        kwargs['synopsis_embeddings'] = torch.FloatTensor(item_synopsis_embeddings[candidate_items]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(user_tensor, item_tensor, **kwargs)\n",
    "        scores = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    \n",
    "    top_indices = np.argsort(scores)[::-1][:k]\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx in top_indices:\n",
    "        item_id = int(candidate_items[idx])\n",
    "        recommendations.append({\n",
    "            'item_id': item_id,\n",
    "            'score': float(scores[idx]),\n",
    "            'rank': len(recommendations) + 1,\n",
    "            'title': get_movie_title(item_id, movies_df),\n",
    "            'genres': get_movie_genres(item_id, movies_df),\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def load_multiple_models(model_paths: Dict[str, str], device: str = DEVICE) -> Dict[str, tuple]:\n",
    "    \"\"\"Load multiple models for comparison.\"\"\"\n",
    "    loaded = {}\n",
    "    for name, path in model_paths.items():\n",
    "        try:\n",
    "            model_obj, checkpoint = NeuMFPlus.load(path, device=device)\n",
    "            model_obj.eval()\n",
    "            loaded[name] = (model_obj, checkpoint)\n",
    "            print(f\"âœ… Loaded: {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to load {name}: {e}\")\n",
    "    return loaded\n",
    "\n",
    "print(\"âœ… Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Genre Features (Optional)\n",
    "\n",
    "If `item_genre_features.npy` is missing, run this cell to generate it from `movies_metadata.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generate Genre Features from Movies Metadata\n",
    "# @markdown Run this cell to generate `item_genre_features.npy` from `movies_metadata.csv`\n",
    "# @markdown\n",
    "# @markdown This script uses the proper ID mapping chain:\n",
    "# @markdown 1. Internal Item ID â†’ MovieLens movieId (from mappings.pkl)\n",
    "# @markdown 2. MovieLens movieId â†’ TMDB ID (from links.csv)\n",
    "# @markdown 3. TMDB ID â†’ Movie metadata (from movies_metadata.csv)\n",
    "\n",
    "import json\n",
    "import ast\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING GENRE FEATURES FROM MOVIES METADATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Load mappings and get reverse item map\n",
    "print(\"\\n[1/6] Loading mappings...\")\n",
    "reverse_item_map = {v: k for k, v in mappings.get('item_id_map', {}).items()}\n",
    "print(f\"   Items in mapping: {len(reverse_item_map):,}\")\n",
    "\n",
    "# Step 2: Load links.csv for MovieLens -> TMDB mapping\n",
    "print(\"\\n[2/6] Loading links.csv...\")\n",
    "links_path = os.path.join(DATASETS_DIR, \"links.csv\")\n",
    "if not os.path.exists(links_path):\n",
    "    print(f\"âŒ links.csv not found at: {links_path}\")\n",
    "    print(\"   Please ensure the MovieLens dataset is properly extracted.\")\n",
    "else:\n",
    "    links_df = pd.read_csv(links_path)\n",
    "    # Create MovieLens -> TMDB mapping\n",
    "    movielens_to_tmdb = {}\n",
    "    for _, row in links_df.iterrows():\n",
    "        if pd.notna(row['tmdbId']):\n",
    "            movielens_to_tmdb[int(row['movieId'])] = int(row['tmdbId'])\n",
    "    print(f\"   MovieLens->TMDB mappings: {len(movelens_to_tmdb):,}\")\n",
    "\n",
    "# Step 3: Load movies metadata\n",
    "print(\"\\n[3/6] Loading movies_metadata.csv...\")\n",
    "metadata_path = os.path.join(DATASETS_DIR, \"movies_metadata.csv\")\n",
    "if not os.path.exists(metadata_path):\n",
    "    print(f\"âŒ movies_metadata.csv not found at: {metadata_path}\")\n",
    "else:\n",
    "    movies_metadata_df = pd.read_csv(metadata_path, low_memory=False)\n",
    "    # Clean TMDB ID column\n",
    "    movies_metadata_df['id'] = pd.to_numeric(movies_metadata_df['id'], errors='coerce')\n",
    "    movies_metadata_df = movies_metadata_df[movies_metadata_df['id'].notna()]\n",
    "    movies_metadata_df['id'] = movies_metadata_df['id'].astype(int)\n",
    "    movies_metadata_df = movies_metadata_df.set_index('id')\n",
    "    print(f\"   Movies loaded: {len(movies_metadata_df):,}\")\n",
    "\n",
    "# Step 4: Extract all unique genres from metadata\n",
    "print(\"\\n[4/6] Extracting unique genres...\")\n",
    "def parse_genres_from_json(genres_str):\n",
    "    \"\"\"Parse genres from JSON or Python list string.\"\"\"\n",
    "    if pd.isna(genres_str) or genres_str == \"\":\n",
    "        return []\n",
    "    try:\n",
    "        genres = json.loads(genres_str)\n",
    "        return [g[\"name\"] for g in genres]\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        pass\n",
    "    try:\n",
    "        genres = ast.literal_eval(genres_str)\n",
    "        return [g[\"name\"] for g in genres]\n",
    "    except (ValueError, SyntaxError, KeyError, TypeError):\n",
    "        return []\n",
    "\n",
    "all_genres = set()\n",
    "for genres_str in movies_metadata_df[\"genres\"].dropna():\n",
    "    genres = parse_genres_from_json(genres_str)\n",
    "    all_genres.update(genres)\n",
    "\n",
    "# Use genre names from mappings if available\n",
    "if GENRE_NAMES:\n",
    "    genre_list = GENRE_NAMES\n",
    "    print(f\"   Using genre names from mappings: {len(genre_list)}\")\n",
    "else:\n",
    "    genre_list = sorted(list(all_genres))\n",
    "    print(f\"   Extracted genres: {len(genre_list)}\")\n",
    "    print(f\"   Genres: {genre_list}\")\n",
    "\n",
    "# Step 5: Generate genre features array\n",
    "print(\"\\n[5/6] Generating genre features array...\")\n",
    "print(f\"   Shape: ({NUM_ITEMS}, {len(genre_list)})\")\n",
    "\n",
    "genre_features = np.zeros((NUM_ITEMS, len(genre_list)), dtype=np.float32)\n",
    "\n",
    "# Track statistics\n",
    "movies_with_genres = 0\n",
    "items_matched = 0\n",
    "genre_counts = {g: 0 for g in genre_list}\n",
    "\n",
    "# Fill genre features for each item\n",
    "for internal_item_id in range(NUM_ITEMS):\n",
    "    # Step 1: Internal -> MovieLens\n",
    "    movielens_id = reverse_item_map.get(internal_item_id)\n",
    "    if movielens_id is None:\n",
    "        continue\n",
    "\n",
    "    # Step 2: MovieLens -> TMDB\n",
    "    tmdb_id = movielens_to_tmdb.get(movelens_id)\n",
    "    if tmdb_id is None:\n",
    "        continue\n",
    "\n",
    "    # Step 3: TMDB -> Metadata\n",
    "    if tmdb_id not in movies_metadata_df.index:\n",
    "        continue\n",
    "\n",
    "    # Parse genres for this movie\n",
    "    genres_str = movies_metadata_df.loc[tmdb_id, 'genres']\n",
    "    genres = parse_genres_from_json(genres_str)\n",
    "\n",
    "    if genres:\n",
    "        movies_with_genres += 1\n",
    "        items_matched += 1\n",
    "\n",
    "        # Set multi-hot encoding for each genre\n",
    "        for genre in genres:\n",
    "            if genre in genre_list:\n",
    "                genre_idx = genre_list.index(genre)\n",
    "                genre_features[internal_item_id, genre_idx] = 1.0\n",
    "                genre_counts[genre] += 1\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATION COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Movies with genre info: {movies_with_genres:,} / {len(movies_metadata_df):,}\")\n",
    "print(f\"  Items matched: {items_matched:,} / {NUM_ITEMS:,}\")\n",
    "print(f\"  Coverage: {items_matched/NUM_ITEMS*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nGenre distribution:\")\n",
    "for genre, count in sorted(genre_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "    pct = count / items_matched * 100 if items_matched > 0 else 0\n",
    "    print(f\"  {genre:20s}: {count:6,} items ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nArray info:\")\n",
    "print(f\"  Shape: {genre_features.shape}\")\n",
    "print(f\"  Non-zero elements: {np.count_nonzero(genre_features):,}\")\n",
    "print(f\"  Sparsity: {(1 - np.count_nonzero(genre_features) / genre_features.size) * 100:.1f}%\")\n",
    "\n",
    "# Step 6: Save\n",
    "genre_output_path = os.path.join(DATA_DIR, \"item_genre_features.npy\")\n",
    "print(f\"\\n[6/6] Saving to: {genre_output_path}\")\n",
    "os.makedirs(os.path.dirname(genre_output_path), exist_ok=True)\n",
    "np.save(genre_output_path, genre_features)\n",
    "\n",
    "# Also save metadata for reference\n",
    "metadata_output_path = os.path.join(DATA_DIR, \"item_genre_features_metadata.pkl\")\n",
    "metadata = {\n",
    "    'num_items': NUM_ITEMS,\n",
    "    'num_genres': len(genre_list),\n",
    "    'genre_names': genre_list,\n",
    "    'items_with_genres': items_matched,\n",
    "    'genre_counts': genre_counts,\n",
    "}\n",
    "with open(metadata_output_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(f\"âœ… Genre features saved successfully!\")\n",
    "print(f\"   File: {genre_output_path}\")\n",
    "print(f\"   Size: {os.path.getsize(genre_output_path) / (1024*1024):.1f} MB\")\n",
    "print(f\"   Metadata: {metadata_output_path}\")\n",
    "\n",
    "# Update global variable\n",
    "GENRE_FEATURES = genre_features\n",
    "print(f\"\\nâœ… Genre features loaded into memory for immediate use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define helper functions (FIXED - with reverse mapping)\n",
    "\n",
    "# Import reverse mapping from loaded data\n",
    "reverse_item_map = {v: k for k, v in mappings.get('item_id_map', {}).items()}\n",
    "\n",
    "def get_movie_title(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
    "    \"\"\"Get movie title for internal item ID.\"\"\"\n",
    "    if movies_df is None:\n",
    "        return f\"Movie {item_id}\"\n",
    "    \n",
    "    # Convert internal item_id to TMDB ID\n",
    "    tmdb_id = reverse_item_map.get(item_id)\n",
    "    if tmdb_id is None:\n",
    "        return f\"Movie {item_id}\"\n",
    "    \n",
    "    # Try to get title from movies_df using TMDB ID\n",
    "    if tmdb_id in movies_df.index:\n",
    "        title = movies_df.loc[tmdb_id, 'title']\n",
    "        return title if pd.notna(title) else f\"Movie {item_id}\"\n",
    "    \n",
    "    return f\"Movie {item_id}\"\n",
    "\n",
    "\n",
    "def parse_genres(genres_str: str) -> list:\n",
    "    \"\"\"Parse genres from JSON string.\"\"\"\n",
    "    import json\n",
    "    import ast\n",
    "    \n",
    "    if pd.isna(genres_str) or genres_str == \"\":\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        genres = json.loads(genres_str)\n",
    "        return [g['name'] for g in genres]\n",
    "    except:\n",
    "        try:\n",
    "            genres = ast.literal_eval(genres_str)\n",
    "            return [g['name'] for g in genres]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "\n",
    "def get_movie_genres(item_id: int, movies_df: Optional[pd.DataFrame] = None) -> str:\n",
    "    \"\"\"Get genres for internal item ID.\"\"\"\n",
    "    global GENRE_FEATURES, GENRE_NAMES\n",
    "    \n",
    "    # First try: Use genre features array (most reliable)\n",
    "    if GENRE_FEATURES is not None and item_id < len(GENRE_FEATURES):\n",
    "        genre_indices = [i for i, g in enumerate(GENRE_FEATURES[item_id]) if g == 1]\n",
    "        if genre_indices and GENRE_NAMES:\n",
    "            return ', '.join([GENRE_NAMES[i] for i in genre_indices if i < len(GENRE_NAMES)])\n",
    "    \n",
    "    # Second try: Get from movies_df using TMDB ID mapping\n",
    "    if movies_df is not None:\n",
    "        tmdb_id = reverse_item_map.get(item_id)\n",
    "        if tmdb_id is not None and tmdb_id in movies_df.index:\n",
    "            genres_str = movies_df.loc[tmdb_id, 'genres']\n",
    "            genres = parse_genres(genres_str)\n",
    "            if genres:\n",
    "                return ', '.join(genres)\n",
    "    \n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def predict_score(model, user_id: int, item_id: int, \n",
    "                genre_vector: Optional[np.ndarray] = None,\n",
    "                synopsis_embedding: Optional[np.ndarray] = None,\n",
    "                device: str = DEVICE) -> float:\n",
    "    \"\"\"Predict score for a user-item pair.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    user_tensor = torch.LongTensor([user_id]).to(device)\n",
    "    item_tensor = torch.LongTensor([item_id]).to(device)\n",
    "    \n",
    "    kwargs = {}\n",
    "    if genre_vector is not None:\n",
    "        kwargs['genre_features'] = torch.FloatTensor([genre_vector]).to(device)\n",
    "    if synopsis_embedding is not None:\n",
    "        kwargs['synopsis_embeddings'] = torch.FloatTensor([synopsis_embedding]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(user_tensor, item_tensor, **kwargs)\n",
    "        score = torch.sigmoid(logits).squeeze(-1).item()\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def recommend(model, user_id: int, k: int = 10,\n",
    "             item_genre_features: Optional[np.ndarray] = None,\n",
    "             item_synopsis_embeddings: Optional[np.ndarray] = None,\n",
    "             seen_items: Optional[List[int]] = None,\n",
    "             device: str = DEVICE) -> List[Dict]:\n",
    "    \"\"\"Recommend top-K items for a user.\"\"\"\n",
    "    model.eval()\n",
    "    num_items = model.num_items\n",
    "    \n",
    "    candidate_items = list(range(num_items))\n",
    "    if seen_items is not None:\n",
    "        candidate_items = [item for item in candidate_items if item not in seen_items]\n",
    "    \n",
    "    user_tensor = torch.LongTensor([user_id] * len(candidate_items)).to(device)\n",
    "    item_tensor = torch.LongTensor(candidate_items).to(device)\n",
    "    \n",
    "    kwargs = {}\n",
    "    if item_genre_features is not None:\n",
    "        kwargs['genre_features'] = torch.FloatTensor(item_genre_features[candidate_items]).to(device)\n",
    "    if item_synopsis_embeddings is not None:\n",
    "        kwargs['synopsis_embeddings'] = torch.FloatTensor(item_synopsis_embeddings[candidate_items]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(user_tensor, item_tensor, **kwargs)\n",
    "        scores = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    \n",
    "    top_indices = np.argsort(scores)[::-1][:k]\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx in top_indices:\n",
    "        item_id = int(candidate_items[idx])\n",
    "        recommendations.append({\n",
    "            'item_id': item_id,\n",
    "            'score': float(scores[idx]),\n",
    "            'rank': len(recommendations) + 1,\n",
    "            'title': get_movie_title(item_id, movies_df),\n",
    "            'genres': get_movie_genres(item_id, movies_df),\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def load_multiple_models(model_paths: Dict[str, str], device: str = DEVICE) -> Dict[str, tuple]:\n",
    "    \"\"\"Load multiple models for comparison.\"\"\"\n",
    "    loaded = {}\n",
    "    for name, path in model_paths.items():\n",
    "        try:\n",
    "            model_obj, checkpoint = NeuMFPlus.load(path, device=device)\n",
    "            model_obj.eval()\n",
    "            loaded[name] = (model_obj, checkpoint)\n",
    "            print(f\"âœ… Loaded: {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to load {name}: {e}\")\n",
    "    return loaded\n",
    "\n",
    "print(\"âœ… Helper functions defined with reverse mapping support!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Get top-K recommendations\n",
    "# @markdown Enter user ID and number of recommendations:\n",
    "\n",
    "user_id_rec = 100  # @param {type:\"integer\"}\n",
    "k_recommendations = 10  # @param {type:\"integer\", min:1, max:50}\n",
    "\n",
    "if user_id_rec >= NUM_USERS:\n",
    "    print(f\"âŒ Invalid user ID. Must be less than {NUM_USERS}.\")\n",
    "else:\n",
    "    recommendations = recommend(\n",
    "        model, user_id_rec, k=k_recommendations,\n",
    "        item_genre_features=GENRE_FEATURES,\n",
    "        item_synopsis_embeddings=SYNOPSIS_EMBEDDINGS,\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"TOP-{k_recommendations} RECOMMENDATIONS FOR USER {user_id_rec}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6} {'Score':<10} {'Title':<50} {'Genres'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        title = rec['title'][:47] + '...' if len(rec['title']) > 47 else rec['title']\n",
    "        print(f\"{rec['rank']:<6} {rec['score']:.4f}     {title:<50} {rec['genres']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Example: Compare Multiple Users\n",
    "\n",
    "See how different users would rate the same movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Compare predictions for multiple users\n",
    "# @markdown Enter item ID and list of user IDs to compare:\n",
    "\n",
    "item_id_compare = 500  # @param {type:\"integer\"}\n",
    "user_ids_compare = \"0, 50, 100, 500, 1000\"  # @param {type:\"string\"}\n",
    "\n",
    "try:\n",
    "    user_list = [int(u.strip()) for u in user_ids_compare.split(',')]\n",
    "except:\n",
    "    user_list = [0, 50, 100, 500, 1000]\n",
    "\n",
    "if item_id_compare >= NUM_ITEMS:\n",
    "    print(f\"âŒ Invalid item ID. Must be less than {NUM_ITEMS}.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(f\"USER COMPARISON FOR ITEM: {get_movie_title(item_id_compare, movies_df)}\")\n",
    "    print(f\"Genres: {get_movie_genres(item_id_compare, movies_df)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n{'User ID':<12} {'Score':<10} {'Prediction'}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    genre_vec = GENRE_FEATURES[item_id_compare] if GENRE_FEATURES is not None else None\n",
    "    synopsis_emb = SYNOPSIS_EMBEDDINGS[item_id_compare] if SYNOPSIS_EMBEDDINGS is not None else None\n",
    "    \n",
    "    for user_id in user_list:\n",
    "        if user_id >= NUM_USERS:\n",
    "            print(f\"{user_id:<12} (invalid user)\")\n",
    "            continue\n",
    "        \n",
    "        score = predict_score(model, user_id, item_id_compare, genre_vec, synopsis_emb)\n",
    "        \n",
    "        if score > 0.8:\n",
    "            prediction = \"Will love it!\"\n",
    "        elif score > 0.6:\n",
    "            prediction = \"Will probably like it\"\n",
    "        elif score > 0.4:\n",
    "            prediction = \"Maybe\"\n",
    "        else:\n",
    "            prediction = \"Probably not interested\"\n",
    "        \n",
    "        print(f\"{user_id:<12} {score:.4f}     {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced: Cold-Start Prediction for New Movies\n",
    "\n",
    "Predict how users would rate a completely new movie using only its content features (genres and synopsis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cold-start prediction for a new movie\n",
    "# @markdown Enter movie details for prediction:\n",
    "\n",
    "new_user_id = 100  # @param {type:\"integer\"}\n",
    "new_movie_genres = \"Action,Sci-Fi\"  # @param {type:\"string\"}\n",
    "new_movie_synopsis = \"A group of astronauts discover a mysterious artifact on Mars that changes their understanding of humanity's place in the universe.\"  # @param {type:\"string\"}\n",
    "\n",
    "if new_user_id >= NUM_USERS:\n",
    "    print(f\"âŒ Invalid user ID. Must be less than {NUM_USERS}.\")\n",
    "else:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    # Load SBERT model for synopsis encoding\n",
    "    print(\"Loading Sentence-BERT model...\")\n",
    "    sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Encode genres\n",
    "    genre_list = [g.strip() for g in new_movie_genres.split(',')]\n",
    "    genre_vector = np.zeros(NUM_GENRES, dtype=np.float32)\n",
    "    \n",
    "    if GENRE_NAMES:\n",
    "        for genre in genre_list:\n",
    "            if genre in GENRE_NAMES:\n",
    "                idx = GENRE_NAMES.index(genre)\n",
    "                genre_vector[idx] = 1.0\n",
    "    \n",
    "    # Encode synopsis\n",
    "    synopsis_embedding = sbert.encode(new_movie_synopsis, show_progress_bar=False)\n",
    "    synopsis_embedding = np.array(synopsis_embedding, dtype=np.float32)\n",
    "    \n",
    "    # Use a placeholder item ID (last item as reference)\n",
    "    placeholder_item_id = NUM_ITEMS - 1\n",
    "    \n",
    "    # Predict\n",
    "    score = predict_score(\n",
    "        model, new_user_id, placeholder_item_id,\n",
    "        genre_vector=genre_vector,\n",
    "        synopsis_embedding=synopsis_embedding\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COLD-START PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nUser ID: {new_user_id}\")\n",
    "    print(f\"\\nNew Movie:\")\n",
    "    print(f\"  Genres: {new_movie_genres}\")\n",
    "    print(f\"  Synopsis: {new_movie_synopsis[:100]}...\")\n",
    "    print(f\"\\nâœ… Predicted score: {score:.4f}\")\n",
    "    \n",
    "    if score > 0.7:\n",
    "        print(\"\\nðŸŽ¬ This user would likely enjoy this movie!\")\n",
    "    elif score > 0.5:\n",
    "        print(\"\\nðŸŽ¬ This user might be interested in this movie.\")\n",
    "    else:\n",
    "        print(\"\\nðŸŽ¬ This movie may not be a good fit for this user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Interactive Recommendation Widget\n",
    "\n",
    "Use this interactive widget to explore recommendations for different users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Debug: Check user interaction history\n",
    "# @markdown Enter user ID to check their interaction history:\n",
    "\n",
    "debug_user_id = 24784  # @param {type:\"integer\"}\n",
    "\n",
    "if debug_user_id >= NUM_USERS:\n",
    "    print(f\"âŒ Invalid user ID. Must be less than {NUM_USERS}.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(f\"USER ANALYSIS: User {debug_user_id}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check if this user has interaction history\n",
    "    # Load training data to check\n",
    "    import pickle\n",
    "    \n",
    "    train_path = os.path.join(DATA_DIR, \"train.pkl\")\n",
    "    val_path = os.path.join(DATA_DIR, \"val.pkl\")\n",
    "    \n",
    "    try:\n",
    "        with open(train_path, 'rb') as f:\n",
    "            train_data = pickle.load(f)\n",
    "        \n",
    "        # Count ratings for this user in training set\n",
    "        user_train_items = train_data['user_item_matrix'][debug_user_id].nonzero()[1]\n",
    "        train_count = len(user_train_items)\n",
    "        \n",
    "        print(f\"\\nTraining set:\")\n",
    "        print(f\"  Items rated: {train_count}\")\n",
    "        \n",
    "        if train_count > 0:\n",
    "            print(f\"  Sample items (first 10): {user_train_items[:10].tolist()}\")\n",
    "            \n",
    "            # Get some sample movie titles\n",
    "            if movies_df is not None and len(user_train_items) > 0:\n",
    "                print(f\"\\n  Sample movies rated by this user:\")\n",
    "                for item_id in user_train_items[:5]:\n",
    "                    title = get_movie_title(item_id, movies_df)\n",
    "                    genres = get_movie_genres(item_id, movies_df)\n",
    "                    print(f\"    - {title} ({genres})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading training data: {e}\")\n",
    "    \n",
    "    # Check validation set\n",
    "    try:\n",
    "        with open(val_path, 'rb') as f:\n",
    "            val_data = pickle.load(f)\n",
    "        \n",
    "        user_val_items = val_data['user_item_matrix'][debug_user_id].nonzero()[1]\n",
    "        val_count = len(user_val_items)\n",
    "        \n",
    "        print(f\"\\nValidation set:\")\n",
    "        print(f\"  Items rated: {val_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading validation data: {e}\")\n",
    "    \n",
    "    total_interactions = train_count + val_count if 'train_count' in locals() else 0\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TOTAL INTERACTIONS: {total_interactions}\")\n",
    "    \n",
    "    if total_interactions == 0:\n",
    "        print(\"\\nâš ï¸  This user has NO interaction history!\")\n",
    "        print(\"   â†’ Model is using default/popularity-based recommendations\")\n",
    "        print(\"   â†’ Try a user with more interactions (e.g., user 100, 500, 1000)\")\n",
    "    elif total_interactions < 10:\n",
    "        print(\"\\nâš ï¸  This user has very few interactions!\")\n",
    "        print(\"   â†’ Recommendations may not be very personalized\")\n",
    "        print(\"   â†’ Consider using a user with more history\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… This user has good interaction history ({total_interactions} items)\")\n",
    "        print(\"   â†’ Recommendations should be personalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find users with good interaction history\n",
    "# @markdown This will find users with many ratings to test personalized recommendations.\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINDING ACTIVE USERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load training data\n",
    "train_path = os.path.join(DATA_DIR, \"train.pkl\")\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# Count interactions per user\n",
    "user_interaction_counts = []\n",
    "for user_id in range(train_data['user_item_matrix'].shape[0]):\n",
    "    count = len(train_data['user_item_matrix'][user_id].nonzero()[1])\n",
    "    user_interaction_counts.append((user_id, count))\n",
    "\n",
    "# Sort by interaction count (descending)\n",
    "user_interaction_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nTop 20 Most Active Users:\")\n",
    "print(f\"{'User ID':<12} {'Ratings':<10} {'Status'}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for user_id, count in user_interaction_counts[:20]:\n",
    "    if count > 100:\n",
    "        status = \"Very Active âœ…\"\n",
    "    elif count > 50:\n",
    "        status = \"Active â­\"\n",
    "    elif count > 20:\n",
    "        status = \"Moderate\"\n",
    "    else:\n",
    "        status = \"Low\"\n",
    "    print(f\"{user_id:<12} {count:<10} {status}\")\n",
    "\n",
    "# Statistics\n",
    "all_counts = [count for _, count in user_interaction_counts]\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STATISTICS:\")\n",
    "print(f\"  Total users: {len(all_counts):,}\")\n",
    "print(f\"  Mean ratings/user: {np.mean(all_counts):.1f}\")\n",
    "print(f\"  Median ratings/user: {np.median(all_counts):.1f}\")\n",
    "print(f\"  Max ratings/user: {np.max(all_counts)}\")\n",
    "print(f\"  Min ratings/user: {np.min(all_counts)}\")\n",
    "\n",
    "# Count by activity level\n",
    "very_active = sum(1 for c in all_counts if c > 100)\n",
    "active = sum(1 for c in all_counts if c > 50)\n",
    "moderate = sum(1 for c in all_counts if c > 20)\n",
    "\n",
    "print(f\"\\nACTIVITY LEVELS:\")\n",
    "print(f\"  Very Active (>100 ratings): {very_active:,} users ({very_active/len(all_counts)*100:.1f}%)\")\n",
    "print(f\"  Active (>50 ratings): {active:,} users ({active/len(all_counts)*100:.1f}%)\")\n",
    "print(f\"  Moderate (>20 ratings): {moderate:,} users ({moderate/len(all_counts)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ SUGGESTION: Try user IDs from the 'Very Active' list above for personalized recommendations!\")\n",
    "print(f\"   Example: User {user_interaction_counts[0][0]} has {user_interaction_counts[0][1]} ratings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
