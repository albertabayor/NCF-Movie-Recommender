{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Preprocessing - With Real Genre Features\n",
    "\n",
    "This notebook runs **FULL preprocessing** with:\n",
    "- Real genre features from TMDB metadata (not dummy zeros!)\n",
    "- Proper user/item mappings\n",
    "- Train/val/test split\n",
    "\n",
    "**Why this matters:**\n",
    "- Current data: Genre = dummy zeros (not useful)\n",
    "- After this: Genre = real multi-hot encoding (actually useful!)\n",
    "- NeuMF+ will benefit from real genre information\n",
    "\n",
    "**Prerequisites:**\n",
    "- Google Drive with: `ratings.csv`, `movies_metadata.csv`, `links.csv`\n",
    "- Colab Pro (T4 GPU, 16GB VRAM)\n",
    "- Estimated time: 30-60 minutes (vs 4-5 hours on local CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✓ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/albertabayor/NCF-Movie-Recommender.git\n",
    "\n",
    "import os\n",
    "os.chdir('NCF-Movie-Recommender')\n",
    "!git pull origin main\n",
    "\n",
    "# Link datasets from Drive\n",
    "!rm -rf datasets\n",
    "!ln -s \"/content/drive/MyDrive/NCF-Movie-Recommender/datasets\" datasets\n",
    "\n",
    "# Link experiments folder\n",
    "!mkdir -p /content/drive/MyDrive/NCF-Movie-Recommender/data\n",
    "!rm -rf data\n",
    "!ln -s /content/drive/MyDrive/NCF-Movie-Recommender/data data\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q torch torchvision pandas numpy scikit-learn tqdm\n",
    "\n",
    "print(\"\\n✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check required files\n",
    "required_files = ['ratings.csv', 'movies_metadata.csv', 'links.csv']\n",
    "datasets_path = 'datasets'\n",
    "\n",
    "print(\"Checking dataset files...\\n\")\n",
    "all_exist = True\n",
    "for filename in required_files:\n",
    "    filepath = os.path.join(datasets_path, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / 1024 / 1024\n",
    "        print(f\"✓ {filename}: {size:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"❌ {filename}: NOT FOUND\")\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n✓ All required files found!\")\n",
    "else:\n",
    "    print(\"\\n❌ Some files are missing. Please upload them to Google Drive first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Full Preprocessing\n",
    "\n",
    "This will:\n",
    "1. Load ratings and filter sparse users/items\n",
    "2. Load metadata and extract **real genres**\n",
    "3. Create user/item mappings\n",
    "4. Split data chronologically (train/val/test)\n",
    "5. Encode genres as multi-hot vectors\n",
    "6. Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from src.preprocessing import DataPreprocessor\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FULL PREPROCESSING - WITH REAL GENRE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis will take 30-60 minutes on Colab T4 GPU\")\n",
    "print(\"\\nSteps:\")\n",
    "print(\"  1. Load and filter ratings\")\n",
    "print(\"  2. Load metadata and extract REAL genres\")\n",
    "print(\"  3. Create user/item mappings\")\n",
    "print(\"  4. Split chronologically\")\n",
    "print(\"  5. Encode genres (multi-hot)\")\n",
    "print(\"  6. Save to Google Drive\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Run full preprocessing\n",
    "preprocessor = DataPreprocessor()\n",
    "preprocessor.run_full()  # Use run_full() for real genres\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n✓ Processed data saved to Google Drive\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - data/train.pkl (with REAL genre features)\")\n",
    "print(\"  - data/val.pkl (with REAL genre features)\")\n",
    "print(\"  - data/test.pkl (with REAL genre features)\")\n",
    "print(\"  - data/mappings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load processed data\n",
    "train_df = pd.read_pickle('data/train.pkl')\n",
    "\n",
    "# Check genre features\n",
    "sample_genres = train_df['genre_features'].head(5).tolist()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION - GENRE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSample genre features (first 5 items):\\n\")\n",
    "\n",
    "# Load genre class names\n",
    "with open('data/mappings.pkl', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "genre_classes = mappings['genre_classes']\n",
    "print(f\"Genre classes ({len(genre_classes)}): {genre_classes}\\n\")\n",
    "\n",
    "for i, genre_vec in enumerate(sample_genres):\n",
    "    active_genres = [genre_classes[j] for j, val in enumerate(genre_vec) if val == 1]\n",
    "    print(f\"Item {i}: {active_genres}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Genre features look good! (not all zeros)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What happened:**\n",
    "1. ✅ Loaded and filtered 25M ratings\n",
    "2. ✅ Extracted REAL genre features from TMDB metadata\n",
    "3. ✅ Created mappings for 256K users and 27K items\n",
    "4. ✅ Split chronologically (70/15/15)\n",
    "5. ✅ Encoded genres as 19-dimensional multi-hot vectors\n",
    "6. ✅ Saved to Google Drive\n",
    "\n",
    "**Next steps:**\n",
    "- Use `colab_training_neumf_plus.ipynb` to train with real genres\n",
    "- NeuMF+ will now benefit from actual genre information\n",
    "- Expected: Better accuracy than dummy genres"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
