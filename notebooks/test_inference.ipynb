{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Testing\n",
    "\n",
    "This notebook tests the trained NeuMF+ models.\n",
    "\n",
    "**Features:**\n",
    "- Load trained model from checkpoint\n",
    "- Verify model configuration (genre/synopsis)\n",
    "- Predict scores for user-item pairs\n",
    "- Generate top-K recommendations\n",
    "- Test genre-only vs genre+synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model, load_mappings, load_features, predict_score, recommend\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Imports loaded!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'inference'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from inference import load_model, load_mappings, load_features, predict_score, recommend\n",
    "\n",
    "print(\"✓ Imports loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "# Handle both local and Colab environments\n",
    "if os.path.exists('inference.py'):\n",
    "    # Running from project root\n",
    "    sys.path.insert(0, '.')\n",
    "elif os.path.exists('../inference.py'):\n",
    "    # Running from notebooks directory\n",
    "    sys.path.insert(0, '..')\n",
    "else:\n",
    "    # Try absolute path\n",
    "    project_root = os.path.abspath('..')\n",
    "    if os.path.exists(os.path.join(project_root, 'inference.py')):\n",
    "        sys.path.insert(0, project_root)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Check if inference module is available\n",
    "try:\n",
    "    from inference import load_model, load_mappings, load_features, predict_score, recommend\n",
    "    print(\"✓ Inference module loaded!\")\n",
    "    print(f\"  Working directory: {os.getcwd()}\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(f\"\\nCurrent working directory: {os.getcwd()}\")\n",
    "    print(f\"\\nPlease check that inference.py exists in the project root.\")\n",
    "    print(\"You may need to navigate to the project directory first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Checkpoint not found: experiments/trained_models/NeuMFPlus_genre_synopsis_best.pt\n",
      "\n",
      "Available checkpoints:\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "checkpoint_path = 'experiments/trained_models/NeuMFPlus_genre_synopsis_best.pt'\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"❌ Checkpoint not found: {checkpoint_path}\")\n",
    "    print(\"\\nAvailable checkpoints:\")\n",
    "    trained_dir = 'experiments/trained_models'\n",
    "    if os.path.exists(trained_dir):\n",
    "        for f in os.listdir(trained_dir):\n",
    "            if f.endswith('.pt'):\n",
    "                print(f\"  - {f}\")\n",
    "else:\n",
    "    model, checkpoint = load_model(checkpoint_path, device='cpu')\n",
    "    config = checkpoint['model_config']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL CONFIGURATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"use_genre: {config.get('use_genre')}\")\n",
    "    print(f\"use_synopsis: {config.get('use_synopsis')}\")\n",
    "    print(f\"use_gated_fusion: {config.get('use_gated_fusion')}\")\n",
    "    print(f\"\\nParameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    if 'metrics' in checkpoint:\n",
    "        metrics = checkpoint['metrics']\n",
    "        print(\"\\nValidation Metrics:\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mappings and features\n",
    "data = load_mappings()\n",
    "features = load_features()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA LOADED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nUsers: {data['num_users']:,}\")\n",
    "print(f\"Items: {data['num_items']:,}\")\n",
    "print(f\"Genres: {len(data['genre_names'])}\")\n",
    "print(f\"\\nGenre names: {data['genre_names']}\")\n",
    "\n",
    "if 'genre_features' in features:\n",
    "    print(f\"\\n✓ Genre features loaded: {features['genre_features'].shape}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Genre features not loaded\")\n",
    "\n",
    "if 'synopsis_embeddings' in features:\n",
    "    print(f\"✓ Synopsis embeddings loaded: {features['synopsis_embeddings'].shape}\")\n",
    "else:\n",
    "    print(\"⚠️  Synopsis embeddings not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Single User-Item Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict score for a specific user-item pair\n",
    "user_id = 100\n",
    "item_id = 500\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"PREDICTION: User {user_id} -> Item {item_id}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare inputs based on model config\n",
    "genre_vector = None\n",
    "synopsis_embedding = None\n",
    "\n",
    "if config.get('use_genre') and 'genre_features' in features:\n",
    "    genre_vector = features['genre_features'][item_id]\n",
    "    print(f\"\\nGenre vector (first 10): {genre_vector[:10]}\")\n",
    "\n",
    "if config.get('use_synopsis') and 'synopsis_embeddings' in features:\n",
    "    synopsis_embedding = features['synopsis_embeddings'][item_id]\n",
    "    print(f\"Synopsis embedding (first 5): {synopsis_embedding[:5]}\")\n",
    "\n",
    "# Predict\n",
    "score = predict_score(\n",
    "    model,\n",
    "    user_id=user_id,\n",
    "    item_id=item_id,\n",
    "    genre_vector=genre_vector,\n",
    "    synopsis_embedding=synopsis_embedding,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Predicted score: {score:.4f}\")\n",
    "print(f\"   (Probability user will like this item)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Top-K Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top-K recommendations for a user\n",
    "user_id = 100\n",
    "k = 10\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"TOP-{k} RECOMMENDATIONS FOR USER {user_id}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recommendations = recommend(\n",
    "    model,\n",
    "    user_id=user_id,\n",
    "    k=k,\n",
    "    item_genre_features=features.get('genre_features'),\n",
    "    item_synopsis_embeddings=features.get('synopsis_embeddings'),\n",
    "    seen_items=None,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(f\"\\n{'Rank':<6} {'Item ID':<10} {'Score':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for rec in recommendations:\n",
    "    print(f\"{rec['rank']:<6} {rec['item_id']:<10} {rec['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Genre-Only vs Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare genre-only vs genre+synopsis\n",
    "if config.get('use_synopsis'):\n",
    "    print(\"=\"*70)\n",
    "    print(\"COMPARISON: Genre-Only vs Genre+Synopsis\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_user = 100\n",
    "    test_item = 500\n",
    "    \n",
    "    # Genre only (synopsis = None or zeros)\n",
    "    score_genre_only = predict_score(\n",
    "        model,\n",
    "        user_id=test_user,\n",
    "        item_id=test_item,\n",
    "        genre_vector=features['genre_features'][test_item],\n",
    "        synopsis_embedding=None,  # No synopsis\n",
    "        device='cpu'\n",
    "    )\n",
    "    \n",
    "    # Genre + Synopsis\n",
    "    score_full = predict_score(\n",
    "        model,\n",
    "        user_id=test_user,\n",
    "        item_id=test_item,\n",
    "        genre_vector=features['genre_features'][test_item],\n",
    "        synopsis_embedding=features['synopsis_embeddings'][test_item],\n",
    "        device='cpu'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nUser {test_user}, Item {test_item}:\")\n",
    "    print(f\"  Genre only:      {score_genre_only:.4f}\")\n",
    "    print(f\"  Genre+Synopsis:  {score_full:.4f}\")\n",
    "    print(f\"  Difference:      {score_full - score_genre_only:+.4f}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Model not trained with synopsis - skipping comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Multiple Users Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions for multiple users\n",
    "test_users = [0, 50, 100, 500, 1000]\n",
    "test_item = 500\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"BATCH PREDICTION: Item {test_item} for Multiple Users\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'User ID':<10} {'Score':<10}\")\n",
    "print(\"-\" * 22)\n",
    "\n",
    "for user_id in test_users:\n",
    "    if user_id >= data['num_users']:\n",
    "        print(f\"{user_id:<10} (invalid user)\")\n",
    "        continue\n",
    "    \n",
    "    score = predict_score(\n",
    "        model,\n",
    "        user_id=user_id,\n",
    "        item_id=test_item,\n",
    "        genre_vector=features.get('genre_features', [None])[test_item] if 'genre_features' in features else None,\n",
    "        synopsis_embedding=features.get('synopsis_embeddings', [None])[test_item] if 'synopsis_embeddings' in features else None,\n",
    "        device='cpu'\n",
    "    )\n",
    "    print(f\"{user_id:<10} {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Tests completed:**\n",
    "1. ✅ Single user-item prediction\n",
    "2. ✅ Top-K recommendations\n",
    "3. ✅ Genre-only vs full model comparison\n",
    "4. ✅ Batch prediction for multiple users\n",
    "\n",
    "**Next steps:**\n",
    "- Test with different users/items\n",
    "- Analyze recommendation quality\n",
    "- Compare different model checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
